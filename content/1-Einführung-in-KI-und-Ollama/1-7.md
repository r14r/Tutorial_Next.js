## 1.7 â€” Grundlagen der Arbeit mit LLMs

### ğŸ“– Hintergrund

Large Language Models (LLMs) sind KI-Modelle, die auf Milliarden von Texten trainiert wurden. Sie lernen, das nÃ¤chste Wort in einem Satz vorherzusagen. Dadurch kÃ¶nnen sie Texte generieren, Fragen beantworten, zusammenfassen. Typische Modelle: GPT-4, Llama-2, Mistral. Ollama ermÃ¶glicht, diese Modelle lokal zu nutzen. Einsatz in KI-Apps: Chatbots, Textzusammenfassungen, Code-Helfer.

### ğŸ’» Code-Beispiele

#### Text-Zusammenfasser mit Ollama

```python
import streamlit as st
import requests

st.title("Dokument-Zusammenfassung mit Ollama")
file = st.file_uploader("Textdatei hochladen", type=["txt"])

if file:
    text = file.read().decode()
    prompt = f"Fasse den folgenden Text in 5 SÃ¤tzen zusammen:\n\n{text}"
    response = requests.post("http://localhost:11434/api/generate",
                             json={"model": "llama2", "prompt": prompt})
    summary = response.json()["response"]
    st.subheader("Zusammenfassung")
    st.write(summary)
```

### ğŸ“ Ãœbungen

1. ErklÃ¤re, warum LLMs nicht immer richtige Antworten geben (Halluzinationen).
2. Schreibe ein Skript, das eine Frage an Ollama stellt und die Antwort ausgibt.

### âœ… LÃ¶sungen

- LLMs basieren auf Wahrscheinlichkeiten und erfinden manchmal plausible, aber falsche Inhalte â†’ â€Halluzinationenâ€œ.

```python
import requests
frage = "Was ist die Hauptstadt von Frankreich?"
r = requests.post("http://localhost:11434/api/generate",
                  json={"model": "llama2", "prompt": frage})
print("Antwort:", r.json()["response"])
```
