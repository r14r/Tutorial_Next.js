# Tag 4 â€” Fortgeschrittene Anwendungen mit LLMs & Daten

## ðŸ“… Zeitplan 09:00 â€“ 15:00

### Ãœbersicht

Der Tag vertieft fortgeschrittene Anwendungen mit LLMs und Datenintegration. Jede Einheit enthÃ¤lt kurze ErklÃ¤rungen, praktische Beispiele und Ãœbungen.

---

### Zeitplan

| Zeit              | Einheit / Inhalt                                                                                   | Dauer   |
|-------------------|----------------------------------------------------------------------------------------------------|---------|
| **09:00 â€“ 09:20** | EinfÃ¼hrung & Ãœberblick  
  Motivation, Ziele des Tages                                                       | 20 min  |
| **09:20 â€“ 10:05** | **Einheit 4.1:** Datenintegration mit Pandas  
  CSV/Excel laden, filtern, LLM-Integration                                         | 45 min  |
| **10:05 â€“ 10:35** | **Einheit 4.2:** Q&A Ã¼ber CSV-Dateien  
  Abfragen, LLM-Antworten, Streamlit-App                                            | 30 min  |
| **10:35 â€“ 11:15** | **Einheit 4.3:** KI-Dashboards mit Streamlit  
  Diagramme, LLM-Kommentare, Gruppenvergleich                                       | 40 min  |
| **11:15 â€“ 11:30** | â˜• **Pause**                                                                                        | 15 min  |
| **11:30 â€“ 12:10** | **Einheit 4.4:** Deployment  
  App starten, requirements.txt, Docker, Streamlit Cloud                            | 40 min  |
| **12:10 â€“ 12:40** | **Einheit 4.5:** Bonus: Q&A Ã¼ber mehrere Datenquellen  
  CSV + FAQ/Text, kombinierte Analyse                                               | 30 min  |
| **12:40 â€“ 13:10** | Ãœbungen & Praxis  
  Eigene Datenquellen, Mini-Projekt starten                                         | 30 min  |
| **13:10 â€“ 14:10** | ðŸ½ï¸ **Mittagspause**                                                                                | 60 min  |
| **14:10 â€“ 14:40** | Mini-Projekt & PrÃ¤sentation  
  App mit mehreren Datenquellen, Q&A, Dashboard                                     | 30 min  |
| **14:40 â€“ 15:00** | Zusammenfassung & Ausblick  
  Reflexion, nÃ¤chste Schritte                                                       | 20 min  |

---

## Ablauf der Einheiten

- **ErklÃ¤rung:** ca. 10â€“15 min
- **Beispiele:** ca. 10 min
- **Ãœbungen:** ca. 15â€“20 min  
    â†’ Ãœbungen werden direkt in Jupyter, VS Code oder Streamlit durchgefÃ¼hrt.

---

## Mini-Projekt (14:10â€“14:40)

Am Ende des Tages wird eine App entwickelt, die folgende Funktionen kombiniert:

- **CSV-Upload**
- **FAQ/Text-Upload**
- **Verarbeitung:** Datenanalyse mit Pandas und LLM
- **Dashboard:** Diagramme, KI-Kommentare
- **Q&A:** Fragen zu kombinierten Datenquellen

---

## Einheit 4.1 â€” Datenintegration mit Pandas

### Beispiele

#### Beispiel 1 â€” CSV laden

```python
import pandas as pd
df = pd.read_csv("sales.csv")
print(df.head())
```

#### Beispiel 2 â€” Excel laden

```python
df = pd.read_excel("data.xlsx")
print(df.shape)
```

#### Beispiel 3 â€” Filterung

```python
kunden = df[df["Country"] == "Germany"]
print(kunden)
```

#### Beispiel 4 â€” LLM-Integration

```python
import requests
stats = df.describe().to_string()
prompt = f"Analysiere die Verkaufsdaten:\n{stats}"
r = requests.post("http://localhost:11434/api/generate",
                  json={"model": "llama2", "prompt": prompt})
print(r.json()["response"])
```

### Ãœbungen

- Lade eine CSV mit Spalten Name, Alter, Einkommen. Berechne den Median des Einkommens.
- Filtere alle Kunden Ã¼ber 40 Jahre.
- Schicke die Statistik an Ollama und bitte um eine wirtschaftliche Interpretation.
- Sortiere die Kunden nach Einkommen absteigend.

### LÃ¶sungen

```python
df = pd.read_csv("kunden.csv")
print(df["Einkommen"].median())
print(df[df["Alter"] > 40])
stats = df.describe().to_string()
prompt = f"Welche wirtschaftlichen Trends lassen sich erkennen?\n{stats}"
print(df.sort_values("Einkommen", ascending=False))
```

---

## Einheit 4.2 â€” Q&A Ã¼ber CSV-Dateien

### Beispiele

#### Beispiel 1 â€” Einfache Abfrage

```python
frage = "Wie viele Kunden sind Ã¤lter als 30?"
antwort = len(df[df["Alter"] > 30])
print(antwort)
```

#### Beispiel 2 â€” Antwort mit LLM

```python
stats = df.describe().to_string()
prompt = f"""Beantworte die Frage basierend auf diesen Daten:
{stats}
Frage: Wie viele Kunden sind Ã¤lter als 30?"""
```

#### Beispiel 3 â€” Streamlit-App

```python
import streamlit as st

file = st.file_uploader("CSV hochladen", type="csv")
if file:
    df = pd.read_csv(file)
    frage = st.text_input("Frage:")
    if frage:
        stats = df.describe().to_string()
        prompt = f"{frage}\nDaten:\n{stats}"
        r = requests.post("http://localhost:11434/api/generate",
                          json={"model": "llama2", "prompt": prompt})
        st.write("Antwort:", r.json()["response"])
```

### Ãœbungen

- Implementiere: â€žWie viele verschiedene StÃ¤dte gibt es in der CSV?â€œ
- Schreibe eine Funktion `answer_question(df, frage)`, die pandas + Ollama kombiniert.
- Teste die Frage: â€žWelcher Kunde hat das hÃ¶chste Einkommen?â€œ

### LÃ¶sungen

```python
# Anzahl StÃ¤dte
print(df["Stadt"].nunique())

# Funktion
def answer_question(df, frage):
    stats = df.describe().to_string()
    prompt = f"Frage: {frage}\nDaten:\n{stats}"
    r = requests.post("http://localhost:11434/api/generate",
                      json={"model": "llama2", "prompt": prompt})
    return r.json()["response"]

print(answer_question(df, "Was ist der Durchschnitt des Alters?"))

# Pandas-LÃ¶sung
print(df.loc[df["Einkommen"].idxmax()])
```

---

## Einheit 4.3 â€” KI-Dashboards mit Streamlit

### Beispiele

#### Beispiel 1 â€” Balkendiagramm

```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
df["Sales"].plot(kind="bar", ax=ax)
st.pyplot(fig)
```

#### Beispiel 2 â€” Histogramm

```python
fig, ax = plt.subplots()
df["Age"].hist(ax=ax, bins=10)
st.pyplot(fig)
```

#### Beispiel 3 â€” LLM-Kommentar

```python
stats = df.describe().to_string()
prompt = f"ErklÃ¤re die wichtigsten Trends:\n{stats}"
```

#### Beispiel 4 â€” Vergleich zweier Gruppen

```python
city1, city2 = "Berlin", "Hamburg"
df1 = df[df["City"] == city1]
df2 = df[df["City"] == city2]
prompt = f"Vergleiche {city1} und {city2}:\n{df1.describe().to_string()}\n{df2.describe().to_string()}"
```

### Ãœbungen

- Erstelle ein Dashboard mit Altersverteilung (Histogramm) und LLM-Analyse.
- Baue ein Dropdown, um zwischen Umsatzdiagramm und Altersdiagramm zu wechseln.
- FÃ¼ge eine Funktion hinzu: â€žVergleiche MÃ¤nner vs. Frauen im Einkommenâ€œ.

### LÃ¶sungen

```python
# Histogramm
fig, ax = plt.subplots()
df["Age"].hist(ax=ax)
st.pyplot(fig)

# Auswahl
chart = st.selectbox("Diagramm wÃ¤hlen", ["Umsatz", "Alter"])
if chart == "Umsatz":
    df["Sales"].plot(kind="bar")
else:
    df["Age"].hist()

# Geschlechtervergleich
male = df[df["Gender"] == "Male"]
female = df[df["Gender"] == "Female"]
prompt = f"Vergleiche Einkommen von MÃ¤nnern und Frauen:\n{male.describe()}\n{female.describe()}"
```

---

## Einheit 4.4 â€” Deployment

### Beispiele

#### Beispiel 1 â€” App starten

```bash
streamlit run app.py
```

#### Beispiel 2 â€” requirements.txt

```
streamlit
pandas
requests
matplotlib
```

#### Beispiel 3 â€” Dockerfile

```dockerfile
FROM python:3.10
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

#### Beispiel 4 â€” Deployment mit Docker

```bash
docker build -t myapp .
docker run -p 8501:8501 myapp
```

### Ãœbungen

- Erstelle requirements.txt fÃ¼r deine eigene App.
- Baue ein Docker-Image und starte es lokal.
- Starte die App auf Streamlit Cloud (GitHub â†’ Streamlit Cloud).

### LÃ¶sungen

```text
# requirements.txt
streamlit
pandas
requests

# Docker
docker build -t meine-app .
docker run -p 8501:8501 meine-app
```

---

## Einheit 4.5 â€” Bonus: Q&A Ã¼ber mehrere Datenquellen

### Beispiele

#### Beispiel 1 â€” CSV + FAQ

```python
faq = "Q: Was ist KI? A: Maschinen, die wie Menschen denken."
stats = df.describe().to_string()
prompt = f"""Beantworte die Frage basierend auf diesen Quellen:
FAQ: {faq}
CSV-Daten: {stats}
Frage: Was ist das Durchschnittsalter?"""
```

#### Beispiel 2 â€” CSV + Textdokument

```python
doc = open("info.txt").read()
prompt = f"""Verwende CSV + Dokument:
CSV: {df.describe().to_string()}
Dokument: {doc}
Frage: Welche Erkenntnisse gibt es?"""
```

### Ãœbungen

- Lade eine CSV mit Kundendaten und kombiniere sie mit einer FAQ-Datei.
- Schreibe eine App, die beide Quellen gleichzeitig analysiert.
- Stelle die Frage: â€žWelche Stadt hat den hÃ¶chsten Umsatz und wie passt das zu den FAQ-Daten?â€œ

### LÃ¶sungen

```python
faq = open("faq.txt").read()
stats = df.describe().to_string()
frage = "Welche Stadt hat den hÃ¶chsten Umsatz und wie passt das zu den FAQ-Daten?"

prompt = f"""FAQ: {faq}
CSV: {stats}
Frage: {frage}"""
```

---

## Zusammenfassung Tag 4 (erweitert)

Nach Tag 4 kÃ¶nnen Studierende:

- CSV/Excel mit Pandas verarbeiten
- LLMs fÃ¼r Q&A Ã¼ber Daten nutzen
- Dashboards mit Diagrammen + KI-Kommentaren bauen
- Apps deployen (Streamlit Cloud, Docker)
- Mehrere Datenquellen kombinieren
