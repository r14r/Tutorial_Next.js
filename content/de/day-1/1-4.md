## Einheit 4 â€” Ollama API mit der Kommandozeile (cURL)

### ğŸ“– Hintergrund

Ollama lÃ¤uft standardmÃ¤ÃŸig auf Port 11434 und bietet eine REST-API. Mit `curl` lassen sich Requests direkt aus der Shell stellen â€“ ideal zum Testen.

### ğŸ’» Beispiele

```sh
# 1. Gesundheitscheck
curl http://localhost:11434

# 2. Einfacher Chat mit llama2
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Nenne drei Programmiersprachen"
}'
```

Antwort-Beispiel (JSON):

```json
{"response": "Python, Java, C++"}
```

#### Chat-API Beispiel

```sh
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [{"role": "user", "content": "ErklÃ¤re maschinelles Lernen in einfachen Worten."}]
}'
```

### ğŸ“ Ãœbungen

1. Nutze curl, um eine Liste aller Modelle von der API abzurufen (`/api/tags`).
2. Sende mit curl einen Prompt: â€Schreibe ein Gedicht Ã¼ber Programmierer.â€œ

### âœ… LÃ¶sungen

```sh
# 1. Modell-Liste
curl http://localhost:11434/api/tags

# 2. Gedicht
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Schreibe ein Gedicht Ã¼ber Programmierer."
}'
```

---

