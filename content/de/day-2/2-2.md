## Einheit 2 — Was ist ein Prompt?

### Umfangreiche Beschreibung & Grundlagen

Ein Prompt ist die Eingabe, mit der ein Mensch ein Sprachmodell (LLM) steuert. Er ist die „Frage“ oder „Anweisung“, die das Modell beantwortet. Die Qualität und Klarheit des Prompts bestimmen maßgeblich die Qualität der Antwort. Ein Prompt kann eine einfache Frage, eine komplexe Aufgabenstellung oder eine detaillierte Anweisung sein. Gute Prompts sind präzise, enthalten Kontext und geben das gewünschte Ausgabeformat vor.

**Elemente eines guten Prompts:**

- **Rolle:** In welcher Rolle soll das Modell antworten? (z. B. „Du bist ein Lehrer…“)
- **Kontext:** Hintergrundinformationen oder Daten, auf die sich die Antwort beziehen soll
- **Aufgabe:** Die eigentliche Anweisung (z. B. „Fasse den Text zusammen“)
- **Format:** Gewünschte Ausgabeform (z. B. Bulletpoints, JSON, Tabelle)

**Warum ist Prompt Engineering wichtig?**

- Unterschiedliche Formulierungen führen zu unterschiedlichen Ergebnissen.
- Ein klarer Prompt reduziert Missverständnisse und Fehler.
- Mit gezielten Prompts kann man das Modell zu besseren, strukturierteren Antworten führen.

### 5 Beispiele für Prompts (mit Python-Code)

1. **Einfache Frage:**

    Prompt:

    ```prompt
        "Was ist künstliche Intelligenz?"
    ```

    ```python
    # Datei: prompt1_einfache_frage.py
    from lib.helper_ollama import ollama
    prompt = "Was ist künstliche Intelligenz?"
    result = ollama.generate(prompt)
    print(result)
    ```

2. **Rolle vorgeben:**

    +Prompt: "Du bist ein Mathematiklehrer. Erkläre den Satz des Pythagoras."

    ```python
    # Datei: prompt2_rolle.py
    from lib.helper_ollama import ollama
    prompt = "Du bist ein Mathematiklehrer. Erkläre den Satz des Pythagoras."
    result = ollama.generate(prompt)
    print(result)
    ```

3. **Kontext einbauen:**

    Prompt: "Hier ist ein Text: 'Python ist eine Programmiersprache...'. Fasse ihn in 2 Sätzen zusammen."

    ```python
    # Datei: prompt3_kontext.py
    from lib.helper_ollama import ollama
    text = "Python ist eine Programmiersprache..."
    prompt = f"Hier ist ein Text: '{text}'. Fasse ihn in 2 Sätzen zusammen."
    result = ollama.generate(prompt)
    print(result)
    ```

4. **Format anfordern:**

    Prompt: "Nenne drei Vorteile von Solarenergie als nummerierte Liste."

    ```python
    # Datei: prompt4_format.py
    from lib.helper_ollama import ollama
    prompt = "Nenne drei Vorteile von Solarenergie als nummerierte Liste."
    result = ollama.generate(prompt)
    print(result)
    ```

5. **Kombinierte Aufgabe:**

    Prompt: "Du bist ein Reiseberater. Empfiehl mir 3 Reiseziele in Italien und gib zu jedem eine kurze Begründung als Tabelle."

    ```python
    # Datei: prompt5_kombiniert.py
    from lib.helper_ollama import ollama
    prompt = "Du bist ein Reiseberater. Empfiehl mir 3 Reiseziele in Italien und gib zu jedem eine kurze Begründung als Tabelle."
    result = ollama.generate(prompt)
    print(result)
    ```

### 10 Fragen & Lösungen zu Prompts

1. **Was ist ein Prompt?**

    *Lösung:* Die Eingabe/Aufforderung, die ein Mensch einem LLM gibt.
2. **Nenne zwei wichtige Elemente eines guten Prompts.**

    *Lösung:* Rolle, Kontext, Aufgabe, Format (je zwei nennen)
3. **Warum ist die Formulierung des Prompts wichtig?**

    *Lösung:* Sie beeinflusst die Qualität und Genauigkeit der Antwort.
4. **Wie kann man das gewünschte Ausgabeformat vorgeben?**

*Lösung:* Indem man es explizit im Prompt beschreibt (z. B. „als Tabelle“).
5. **Was passiert, wenn ein Prompt zu vage ist?**

*Lösung:* Das Modell gibt oft ungenaue oder unerwünschte Antworten.
6. **Wie kann man Kontext in einen Prompt einbauen?**

*Lösung:* Durch Hinzufügen von Hintergrundinformationen oder Beispielen.
7. **Was ist ein Beispiel für einen Prompt mit Rolle?**

*Lösung:* „Du bist ein Lehrer. Erkläre...“
8. **Wie kann man das Modell zu einer strukturierten Antwort bringen?**

*Lösung:* Durch Vorgabe des Formats (z. B. Bulletpoints, JSON)
9. **Was ist Prompt Engineering?**

*Lösung:* Die Kunst, Prompts so zu gestalten, dass das Modell optimale Ergebnisse liefert.
10. **Wie kann man die Antwort eines LLMs gezielt steuern?**

*Lösung:* Durch präzise, klare und formatierte Prompts.

---

