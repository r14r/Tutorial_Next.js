## Einheit 8 — Fehler & Grenzen von LLMs

### Umfangreiche Beschreibung & Grundlagen

LLMs sind leistungsstark, aber sie haben klare Grenzen und machen typische Fehler. Sie können keine echten Fakten nachschlagen, sondern erzeugen Antworten auf Basis von Wahrscheinlichkeiten und Mustern aus den Trainingsdaten. Zu den wichtigsten Fehlerquellen gehören:

- **Halluzinationen:** Das Modell erfindet plausible, aber falsche Informationen.
- **Bias:** Vorurteile und Stereotype aus den Trainingsdaten werden übernommen.
- **Mathematische Fehler:** LLMs sind keine Rechenmaschinen und machen oft Fehler bei komplexen Berechnungen.
- **Kontextfenster:** Das Modell kann sich nur an eine begrenzte Textmenge erinnern. Zu lange Prompts werden abgeschnitten.
- **Veraltetes Wissen:** Das Modell kennt nur Informationen bis zum Stand seines Trainingsdatums.

**Warum ist das wichtig?**

- Man sollte LLM-Antworten immer kritisch prüfen.
- Für sicherheitskritische oder faktenbasierte Aufgaben sind LLMs nur eingeschränkt geeignet.
- Prompt Engineering kann helfen, Fehler zu reduzieren, aber nicht ganz vermeiden.

### 5 Beispiele für Fehler & Grenzen (mit Python-Code)

1. **Halluzination:**

    Prompt:

    ```prompt
    "Was ist die Hauptstadt von Frankreich in Afrika?"
    ```

    ```python
    # Datei: fehler1_halluzination.py
    from lib.helper_ollama import ollama
    prompt = "Was ist die Hauptstadt von Frankreich in Afrika?"
    result = ollama.generate(prompt)
    print(result)
    ```

2. **Bias:**

    Prompt:

    ```prompt
    "Beschreibe einen typischen Programmierer."
    ```

    ```python
    # Datei: fehler2_bias.py
    from lib.helper_ollama import ollama
    prompt = "Beschreibe einen typischen Programmierer."
    result = ollama.generate(prompt)
    print(result)
    ```

3. **Mathematischer Fehler:**

    Prompt:

    ```prompt
    "Was ist 12345 x 6789?"
    ```

    ```python
    # Datei: fehler3_mathe.py
    from lib.helper_ollama import ollama
    prompt = "Was ist 12345 x 6789?"
    result = ollama.generate(prompt)
    print(result)
    ```

4. **Kontextlimit:**

    Prompt:

    ```prompt
    Sehr langer Text, gefolgt von einer Frage zum Anfang des Textes.
    ```

    ```python
    # Datei: fehler4_kontext.py
    from lib.helper_ollama import ollama
    text = "Dies ist ein sehr langer Text ..." * 1000
    prompt = f"{text}\nWas steht am Anfang des Textes?"
    result = ollama.generate(prompt)
    print(result)
    ```

5. **Veraltetes Wissen:**

    Prompt:

    ```prompt
    "Wer ist aktueller Bundeskanzler von Deutschland?" (nach Trainingszeitpunkt)
    ```

    ```python
    # Datei: fehler5_veraltet.py
    from lib.helper_ollama import ollama
    prompt = "Wer ist aktueller Bundeskanzler von Deutschland?"
    result = ollama.generate(prompt)
    print(result)
    ```

### 10 Fragen & Lösungen zu Fehlern & Grenzen

1. **Was ist eine Halluzination bei LLMs?**

*Lösung:* Das Modell erfindet plausible, aber falsche Informationen.
2. **Was ist Bias?**

*Lösung:* Übernommene Vorurteile oder Stereotype aus den Trainingsdaten.
3. **Warum machen LLMs Rechenfehler?**

*Lösung:* Sie sind keine spezialisierten Rechenmaschinen.
4. **Was ist das Kontextfenster?**

*Lösung:* Die maximale Textmenge, die das Modell gleichzeitig verarbeiten kann.
5. **Wie kann man Halluzinationen erkennen?**

*Lösung:* Durch kritisches Prüfen und Gegenrecherche.
6. **Warum ist veraltetes Wissen ein Problem?**

*Lösung:* Das Modell kennt keine Ereignisse nach dem Trainingszeitpunkt.
7. **Wie kann man Bias im Prompting reduzieren?**

*Lösung:* Durch neutrale, ausgewogene Prompts und kritische Prüfung der Antworten.
8. **Was ist ein typischer Fehler bei langen Prompts?**

*Lösung:* Das Modell vergisst den Anfang oder wichtige Details.
9. **Wie kann man mathematische Fehler vermeiden?**

*Lösung:* Ergebnisse mit einem Taschenrechner oder spezialisierter Software prüfen.
10. **Warum sollte man LLM-Antworten immer prüfen?**

*Lösung:* Wegen möglicher Fehler, Halluzinationen und Bias.

---

