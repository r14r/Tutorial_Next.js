# Tag 3 ‚Äî Datenverarbeitung & KI-Anwendungen

## Einheit 0 - Zeitplan 09:00 ‚Äì 15:00

### √úbersicht

Der Tag vermittelt praxisnah die Grundlagen der KI-Textanalyse mit Ollama und Python. Jede Einheit besteht aus einer kurzen Erkl√§rung, Beispielen und praktischen √úbungen.

---

### Zeitplan

| Zeit            | Einheit / Inhalt                                                                 | Dauer   |
|-----------------|----------------------------------------------------------------------------------|---------|
| **09:00 ‚Äì 09:20** | Einf√ºhrung & √úberblick - Motivation, Ziele, KI-Anwendungen      | 20 min  |
| **09:20 ‚Äì 09:50** | **Einheit 3.1:** Einf√ºhrung in Textanalyse - Grundbegriffe, Aufgaben | 30 min  |
| **09:50 ‚Äì 10:30** | **Einheit 3.2:** Sentimentanalyse - Stimmung erkennen, Beispiele, √úbungen | 40 min  |
| **10:30 ‚Äì 11:10** | **Einheit 3.3:** Themenklassifikation - Kategorien, Labeling, √úbungen | 40 min  |
| **11:10 ‚Äì 11:25** | ‚òï **Pause**                                                                    | 15 min  |
| **11:25 ‚Äì 12:00** | **Einheit 3.4:** Schl√ºsselwort-Extraktion - Keywords, Listen, √úbungen | 35 min  |
| **12:00 ‚Äì 12:35** | **Einheit 3.5:** Named Entity Recognition (NER) - Personen, Orte, Organisationen | 35 min  |
| **12:35 ‚Äì 13:35** | üçΩÔ∏è **Mittagspause**                                                            | 60 min  |
| **13:35 ‚Äì 14:05** | **Einheit 3.6:** FAQ-Bot mit Ollama - FAQ-Upload, Bot-Logik, √úbungen | 30 min  |
| **14:05 ‚Äì 14:35** | **Einheit 3.7:** Kombination von Analysen - Sentiment + Keywords + Entities | 30 min  |
| **14:35 ‚Äì 15:00** | **Einheit 3.8:** Analyse-Dashboard mit Streamlit - App bauen, Zusammenfassung | 25 min  |

---



---

## Einheit 1 ‚Äî Einf√ºhrung in Textanalyse

### Umfangreiche Beschreibung & Grundlagen

Textanalyse (Natural Language Processing, NLP) ist ein zentrales Anwendungsfeld der K√ºnstlichen Intelligenz. Sie umfasst Methoden, um aus unstrukturiertem Text strukturierte Informationen zu gewinnen. Typische Aufgaben sind:

- **Klassifikation:** Einordnung von Texten in Themen, Kategorien oder Labels (z. B. Sport, Politik, Technik)
- **Sentimentanalyse:** Bewertung der Stimmung (positiv, negativ, neutral)
- **Schl√ºsselwort-Extraktion:** Herausfiltern der wichtigsten Begriffe
- **Named Entity Recognition (NER):** Erkennen von Eigennamen wie Personen, Orten, Organisationen
- **Zusammenfassung:** Komplexe Texte auf das Wesentliche reduzieren

LLMs (Large Language Models) sind besonders gut f√ºr Textanalyse geeignet, da sie auf riesigen Textmengen trainiert wurden und semantische Zusammenh√§nge erkennen. Sie werden eingesetzt in Business Intelligence, Social Media Monitoring, Chatbots, Kundenfeedback, Suchmaschinen und vielen weiteren Bereichen.

**Warum ist Textanalyse wichtig?**

- Sie hilft, gro√üe Mengen an Text automatisch auszuwerten.
- Sie erm√∂glicht datengetriebene Entscheidungen auf Basis von Textdaten.
- Sie ist Grundlage f√ºr viele moderne KI-Anwendungen.

### 5 Beispiele f√ºr Textanalyse-Aufgaben (mit Python-Code)

1. **Kategorisierung:**

    Text:

    ```text
    "Lionel Messi schoss ein Tor."
    - Aufgabe: Thema erkennen ‚Üí "Sport"
    ```

    ```python
    # Datei: beispiel1_kategorisierung.py
    from lib.helper_ollama import ollama

    text = "Lionel Messi schoss ein Tor."
    prompt = f"Ordne diesen Text einem Thema zu (Sport, Politik, Technik, Unterhaltung): {text}"
    result = ollama.generate(prompt)
    print("Thema:", result)
    ```

2. **Stimmungsanalyse:**

    Text:

    ```text
    "Das Produkt ist gro√üartig!"
    - Aufgabe: Stimmung erkennen ‚Üí "Positiv"
    ```

    ```python
    # Datei: beispiel2_sentiment.py
    from lib.helper_ollama import ollama

    text = "Das Produkt ist gro√üartig!"
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

3. **Schl√ºsselw√∂rter extrahieren:**

    Text:

    ```text
    "Tesla bringt ein neues Elektroauto auf den Markt."
    - Aufgabe: Keywords ‚Üí ["Tesla", "Elektroauto"]
    ```

    ```python
    # Datei: beispiel3_keywords.py
    from lib.helper_ollama import ollama

    text = "Tesla bringt ein neues Elektroauto auf den Markt."
    prompt = f"Extrahiere die wichtigsten Keywords als Python-Liste: {text}"
    result = ollama.generate(prompt)
    print("Keywords:", result)
    ```

4. **Named Entities finden:**

    Text:

    ```text
    "Angela Merkel traf Barack Obama in Berlin."
    - Aufgabe: Personen und Orte erkennen ‚Üí ["Angela Merkel", "Barack Obama", "Berlin"]
    ```

    ```python
    # Datei: beispiel4_entities.py
    from lib.helper_ollama import ollama

    text = "Angela Merkel traf Barack Obama in Berlin."
    prompt = f"Finde Named Entities (Personen, Orte, Organisationen) als JSON: {text}"
    result = ollama.generate(prompt)
    print("Entities:", result)
    ```

5. **Zusammenfassung:**

    Text:

    ```text
    "Die Aktie von Tesla stieg nach der Pr√§sentation eines neuen Modells um 10%."
    - Aufgabe: Kurze Zusammenfassung ‚Üí "Tesla-Aktie steigt nach neuem Modell."
    ```

    ```python
    # Datei: beispiel5_zusammenfassung.py
    from lib.helper_ollama import ollama

    text = "Die Aktie von Tesla stieg nach der Pr√§sentation eines neuen Modells um 10%."
    prompt = f"Fasse den folgenden Text in einem Satz zusammen: {text}"
    result = ollama.generate(prompt)
    print("Zusammenfassung:", result)
    ```

### 10 Fragen & L√∂sungen zu Textanalyse

1. **Was ist Textanalyse?**
    - *L√∂sung:* Die automatische Auswertung und Strukturierung von Texten durch KI.
2. **Nenne zwei typische Aufgaben der Textanalyse.**
    - *L√∂sung:* Klassifikation, Sentimentanalyse, Keyword-Extraktion, NER, Zusammenfassung (je zwei nennen)
3. **Warum sind LLMs f√ºr Textanalyse geeignet?**
    - *L√∂sung:* Sie erkennen semantische Zusammenh√§nge und sind auf gro√üen Textmengen trainiert.
4. **Was ist Sentimentanalyse?**
    - *L√∂sung:* Die Erkennung der Stimmung eines Textes (positiv, negativ, neutral).
5. **Was versteht man unter Named Entity Recognition?**
    - *L√∂sung:* Das Erkennen von Eigennamen wie Personen, Orten, Organisationen.
6. **Wie kann Textanalyse im Business helfen?**
    - *L√∂sung:* Automatische Auswertung von Kundenfeedback, Social Media, Support-Tickets etc.
7. **Was ist ein Beispiel f√ºr eine Klassifikationsaufgabe?**
    - *L√∂sung:* Ein Text wird als "Sport" oder "Politik" klassifiziert.
8. **Wie kann man Schl√ºsselw√∂rter aus Texten extrahieren?**
    - *L√∂sung:* Mit LLMs oder speziellen Algorithmen, z. B. durch Prompts wie "Extrahiere Keywords: ..."
9. **Was ist eine Zusammenfassung?**
    - *L√∂sung:* Die Reduktion eines Textes auf die wichtigsten Aussagen.
10. **Nenne ein Beispiel f√ºr den Einsatz von Textanalyse im Alltag.**
    - *L√∂sung:* Spam-Filter, Chatbots, automatische √úbersetzungen, Produktempfehlungen.

---

## Einheit 2 ‚Äî Sentimentanalyse (Stimmung erkennen)

### Umfangreiche Beschreibung & Grundlagen

Sentimentanalyse ist die automatische Erkennung der Stimmung in Texten. Sie wird h√§ufig in Marketing, Social Media, Produktbewertungen und Kundenfeedback eingesetzt. Ziel ist es, herauszufinden, ob ein Text positiv, negativ oder neutral ist. LLMs sind besonders gut darin, weil sie viele Beispiele aus dem Internet kennen und Sprachnuancen erkennen k√∂nnen.

**Warum ist Sentimentanalyse wichtig?**

- Unternehmen k√∂nnen Trends und Meinungen erkennen.
- Sie hilft, Kundenfeedback automatisch auszuwerten.
- Sie ist Grundlage f√ºr automatisierte Moderation und Monitoring.

**Herausforderungen:**

- Ironie und Sarkasmus sind schwer zu erkennen.
- Gemischte Stimmungen in einem Text (z. B. "Service schlecht, Essen gut")
- Unterschiedliche Formulierungen f√ºr gleiche Gef√ºhle

### 5 Beispiele f√ºr Sentimentanalyse (mit Python-Code)

1. **Einfache Analyse:**

    Text:

    ```text
    "Das Produkt ist super!"
    ```

    Ergebnis:

    ```text
    "Positiv"
    ```

    ```python
    # Datei: sentiment1_einfach.py
    from lib.helper_ollama import ollama

    text = "Das Produkt ist super!"
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

2. **Negatives Feedback:**

    Text:

    ```text
    "Ich bin sehr entt√§uscht von der Qualit√§t."
    ```

    Ergebnis:

    ```text
    "Negativ"
    ```

    ```python
    # Datei: sentiment2_negativ.py
    from lib.helper_ollama import ollama

    text = "Ich bin sehr entt√§uscht von der Qualit√§t."
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

3. **Neutrale Aussage:**

    Text:

    ```text
    "Das Wetter ist heute durchschnittlich."
    ```

    Ergebnis:

    ```text
    "Neutral"
    ```

    ```python
    # Datei: sentiment3_neutral.py
    from lib.helper_ollama import ollama

    text = "Das Wetter ist heute durchschnittlich."
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

4. **Gemischte Stimmung:**

    Text:

    ```text
    "Der Service war langsam, aber das Essen war lecker."
    ```

    Ergebnis:

    ```text
    "Neutral" oder "Gemischt"
    ```

    ```python
    # Datei: sentiment4_gemischt.py
    from lib.helper_ollama import ollama

    text = "Der Service war langsam, aber das Essen war lecker."
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral, Gemischt): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

5. **Ironie/Sarkasmus:**

    Text:

    ```text
    "Toll, schon wieder ein Fehler im System..."
    ```

    Ergebnis:

    ```text
    Modell erkennt evtl. "Negativ"
    ```

    ```python
    # Datei: sentiment5_ironie.py
    from lib.helper_ollama import ollama

    text = "Toll, schon wieder ein Fehler im System..."
    prompt = f"Analysiere die Stimmung (Positiv, Negativ, Neutral, Sarkasmus): {text}"
    result = ollama.generate(prompt)
    print("Stimmung:", result)
    ```

### 10 Fragen & L√∂sungen zu Sentimentanalyse

1. **Was ist Sentimentanalyse?**
    - *L√∂sung:* Die automatische Erkennung der Stimmung in Texten.
2. **Welche Stimmungen werden meist unterschieden?**
    - *L√∂sung:* Positiv, Negativ, Neutral.
3. **Warum ist Sentimentanalyse f√ºr Unternehmen wichtig?**
    - *L√∂sung:* Sie hilft, Meinungen und Trends zu erkennen.
4. **Was ist eine Herausforderung bei Sentimentanalyse?**
    - *L√∂sung:* Ironie, Sarkasmus, gemischte Stimmungen.
5. **Wie kann man die Antwort auf "Positiv", "Negativ" oder "Neutral" beschr√§nken?**
    - *L√∂sung:* Durch explizite Vorgabe im Prompt.
6. **Wie kann man mehrere S√§tze automatisch analysieren?**
    - *L√∂sung:* Mit einer Schleife und einer Funktion wie `analyze_sentiment(text)`.
7. **Was ist ein Beispiel f√ºr einen neutralen Text?**
    - *L√∂sung:* "Das Wetter ist heute durchschnittlich."
8. **Wie kann man Sentimentanalyse in einer App nutzen?**
    - *L√∂sung:* Z. B. mit Streamlit und LLM-API.
9. **Was ist ein Nachteil von LLMs bei Sentimentanalyse?**
    - *L√∂sung:* Sie k√∂nnen Ironie/Sarkasmus oft nicht sicher erkennen.
10. **Wie kann man die Ergebnisse der Sentimentanalyse verbessern?**
    - *L√∂sung:* Durch gezielte Prompts, Beispiele und Nachbearbeitung.

---

## Einheit 3 ‚Äî Themenklassifikation

### Umfangreiche Beschreibung & Grundlagen

Themenklassifikation (Topic Classification) ist die automatische Zuordnung von Texten zu vordefinierten Themen oder Kategorien. LLMs k√∂nnen dies ohne spezielles Training, da sie viele Beispiele aus unterschiedlichen Bereichen kennen. Typische Kategorien sind z. B. Sport, Politik, Wissenschaft, Unterhaltung, Wirtschaft.

**Warum ist Themenklassifikation wichtig?**

- Sie hilft, gro√üe Textmengen zu strukturieren und zu filtern.
- Sie ist Grundlage f√ºr News-Filter, Content-Moderation, Trend-Analysen und mehr.
- Sie erm√∂glicht gezielte Auswertungen und Automatisierung.

**Herausforderungen:**

- Texte k√∂nnen mehrere Themen enthalten.
- Kategorien m√ºssen klar definiert sein.
- Unterschiedliche Formulierungen f√ºr gleiche Themen.

### 5 Beispiele f√ºr Themenklassifikation (mit Python-Code)

1. **Einfache Klassifikation:**

    Text:

    ```text
    "Apple hat ein neues iPhone vorgestellt."
    ```

    Ergebnis:

    ```text
    "Technologie"
    ```

    ```python
    # Datei: topic1_einfach.py
    from lib.helper_ollama import ollama

    text = "Apple hat ein neues iPhone vorgestellt."
    prompt = f"Ordne diesen Text einem Thema zu (Technologie, Politik, Sport, Unterhaltung): {text}"
    result = ollama.generate(prompt)
    print("Thema:", result)
    ```

2. **Politik:**

    Text:

    ```text
    "Die Regierung hat ein neues Gesetz verabschiedet."
    ```

    Ergebnis:

    ```text
    "Politik"
    ```

    ```python
    # Datei: topic2_politik.py
    from lib.helper_ollama import ollama

    text = "Die Regierung hat ein neues Gesetz verabschiedet."
    prompt = f"Ordne diesen Text einem Thema zu (Technologie, Politik, Sport, Unterhaltung): {text}"
    result = ollama.generate(prompt)
    print("Thema:", result)
    ```

3. **Sport:**

    Text:

    ```text
    "Lionel Messi schoss 2 Tore."
    ```

    Ergebnis:

    ```text
    "Sport"
    ```

    ```python
    # Datei: topic3_sport.py
    from lib.helper_ollama import ollama

    text = "Lionel Messi schoss 2 Tore."
    prompt = f"Ordne diesen Text einem Thema zu (Technologie, Politik, Sport, Unterhaltung): {text}"
    result = ollama.generate(prompt)
    print("Thema:", result)
    ```

4. **Mehrdeutiger Text:**

    Text:

    ```text
    "Tesla investiert in neue Batterietechnologie und sponsert ein Fu√üballteam."
    ```

    Ergebnis:

    ```text
    "Technologie, Sport" (Mehrthemen m√∂glich)
    ```

    ```python
    # Datei: topic4_mehrdeutig.py
    from lib.helper_ollama import ollama

    text = "Tesla investiert in neue Batterietechnologie und sponsert ein Fu√üballteam."
    prompt = f"Ordne diesen Text den passenden Themen zu (Technologie, Politik, Sport, Unterhaltung): {text}"
    result = ollama.generate(prompt)
    print("Themen:", result)
    ```

5. **Klassifikation mit JSON-Ausgabe:**

    Text:

    ```text
    "Die Aktie von Tesla stieg um 5%."
    ```

    Ergebnis:

    ```text
    {"Text": "Die Aktie von Tesla stieg um 5%.", "Thema": "Wirtschaft"}
    ```

    ```python
    # Datei: topic5_json.py
    from lib.helper_ollama import ollama

    text = "Die Aktie von Tesla stieg um 5%."
    prompt = f"Klassifiziere den Text und antworte im JSON-Format:\n{{\n  'Text': '{text}',\n  'Thema': '<Kategorie>'\n}}"
    result = ollama.generate(prompt)
    print("Klassifikation:", result)
    ```

### 10 Fragen & L√∂sungen zu Themenklassifikation

1. **Was ist Themenklassifikation?**
    - *L√∂sung:* Die automatische Zuordnung von Texten zu vordefinierten Themen.
2. **Nenne drei typische Themen-Kategorien.**
    - *L√∂sung:* Sport, Politik, Technologie, Wirtschaft, Unterhaltung (je drei nennen)
3. **Warum ist Themenklassifikation n√ºtzlich?**
    - *L√∂sung:* Sie hilft, gro√üe Textmengen zu strukturieren und gezielt auszuwerten.
4. **Wie kann man mehrere Themen in einem Text erkennen?**
    - *L√∂sung:* Durch Prompts, die Mehrfachnennungen erlauben.
5. **Was ist eine Herausforderung bei der Themenklassifikation?**
    - *L√∂sung:* Mehrdeutige oder gemischte Texte.
6. **Wie kann man die Ausgabe strukturieren?**
    - *L√∂sung:* Durch Vorgabe von JSON- oder Listenformat im Prompt.
7. **Wie kann man Themenklassifikation in einer App nutzen?**
    - *L√∂sung:* Z. B. f√ºr News-Filter, Content-Moderation, Trend-Analysen.
8. **Was ist ein Nachteil von zu vielen Kategorien?**
    - *L√∂sung:* Die Zuordnung wird schwieriger und ungenauer.
9. **Wie kann man die Qualit√§t der Klassifikation verbessern?**
    - *L√∂sung:* Durch klare Kategorien und Beispiele im Prompt.
10. **Wie kann man Themenklassifikation mit LLMs testen?**
    - *L√∂sung:* Durch verschiedene Prompts und Vergleich der Ergebnisse.

---

## Einheit 4 ‚Äî Schl√ºsselwort-Extraktion

### Umfangreiche Beschreibung & Grundlagen

Schl√ºsselwort-Extraktion (Keyword Extraction) ist die Aufgabe, aus einem Text die wichtigsten Begriffe oder Phrasen herauszufiltern. Diese Keywords sind zentral f√ºr Suchmaschinen, Zusammenfassungen, Tagging und die schnelle Erfassung von Inhalten. LLMs k√∂nnen automatisch relevante Begriffe erkennen, da sie semantische Zusammenh√§nge verstehen.

**Warum ist Keyword-Extraktion wichtig?**

- Sie hilft, gro√üe Textmengen schnell zu durchsuchen und zu indexieren.
- Sie ist Grundlage f√ºr SEO, Textzusammenfassungen und Datenanalyse.
- Sie unterst√ºtzt die automatische Verschlagwortung und Kategorisierung.

**Herausforderungen:**

- Unterschiedliche Schreibweisen und Synonyme
- Relevanzbewertung: Was ist wirklich wichtig?
- Mehrwortbegriffe (z. B. "K√ºnstliche Intelligenz")

### 5 Beispiele f√ºr Schl√ºsselwort-Extraktion (mit Python-Code)

1. **Einfache Extraktion:**

    Text:

    ```text
    "Tesla bringt ein neues Elektroauto mit innovativer Batterie auf den Markt."
    ````

    Ergebnis:

    ```text
    ["Tesla", "Elektroauto", "Batterie"]
    ```

    ```python
    # Datei: keywords1_einfach.py
    from lib.helper_ollama import ollama

    text = "Tesla bringt ein neues Elektroauto mit innovativer Batterie auf den Markt."
    prompt = f"Extrahiere die wichtigsten Keywords als Python-Liste: {text}"
    result = ollama.generate(prompt)
    print("Keywords:", result)
    ```

2. **Ausgabe als Liste:**

    Text:

    ```text
    "KI ver√§ndert die Medizin durch Bildanalyse und Sprachmodelle."
    ```

    Ergebnis:

    ```text
    ["KI", "Medizin", "Bildanalyse", "Sprachmodelle"]
    ```

    ```python
    # Datei: keywords2_liste.py
    from lib.helper_ollama import ollama

    text = "KI ver√§ndert die Medizin durch Bildanalyse und Sprachmodelle."
    prompt = f"Finde die Keywords und gib sie als Python-Liste zur√ºck. Text: {text}"
    result = ollama.generate(prompt)
    print("Keywords:", result)
    ```

3. **JSON-Ausgabe:**

    Text:

    ```text
    "Die FIFA organisiert die Weltmeisterschaft in Katar."
    ```

    Ergebnis:

    ```text
    {"Keywords": ["FIFA", "Weltmeisterschaft", "Katar"], "Anzahl": 3}
    ```

    ```python
    # Datei: keywords3_json.py
    from lib.helper_ollama import ollama

    text = "Die FIFA organisiert die Weltmeisterschaft in Katar."
    prompt = f"Analysiere den Text und gib zur√ºck: {{'Keywords': [...], 'Anzahl': <int>}} Text: {text}"
    result = ollama.generate(prompt)
    print("Keywords JSON:", result)
    ```

4. **Mehrwortbegriffe:**

    Text:

    ```text
    "K√ºnstliche Intelligenz revolutioniert die Industrie."
    ```

    Ergebnis:

    ```text
    ["K√ºnstliche Intelligenz", "Industrie"]
    ```

    ```python
    # Datei: keywords4_mehrwort.py
    from lib.helper_ollama import ollama

    text = "K√ºnstliche Intelligenz revolutioniert die Industrie."
    prompt = f"Extrahiere alle wichtigen Mehrwortbegriffe und Keywords als Liste: {text}"
    result = ollama.generate(prompt)
    print("Mehrwort-Keywords:", result)
    ```

5. **Vergleich verschiedener Prompts:**

    Prompt 1:

    ```prompt
     "Extrahiere Keywords: ..."
     ```

    Prompt 2:

    ```prompt
    "Gib die wichtigsten Begriffe als Liste zur√ºck: ..."
    ```

    Ergebnis:

    ```text
    Unterschiedliche Formate, aber √§hnliche Inhalte.
    ```

    ```python
    # Datei: keywords5_vergleich.py
    from lib.helper_ollama import ollama

    text = "KI und Robotik ver√§ndern die Arbeitswelt."
    prompt1 = f"Extrahiere Keywords: {text}"
    prompt2 = f"Gib die wichtigsten Begriffe als Liste zur√ºck: {text}"
    result1 = ollama.generate(prompt1)
    result2 = ollama.generate(prompt2)
    print("Prompt 1 Ergebnis:", result1)
    print("Prompt 2 Ergebnis:", result2)
    ```

### 10 Fragen & L√∂sungen zu Schl√ºsselwort-Extraktion

1. **Was ist Schl√ºsselwort-Extraktion?**
    - *L√∂sung:* Das Herausfiltern der wichtigsten Begriffe aus einem Text.
2. **Wof√ºr werden Keywords verwendet?**
    - *L√∂sung:* Suchmaschinen, Zusammenfassungen, Tagging, Datenanalyse.
3. **Wie kann man Keywords mit LLMs extrahieren?**
    - *L√∂sung:* Durch gezielte Prompts wie "Extrahiere Keywords: ..."
4. **Was ist eine Herausforderung bei der Keyword-Extraktion?**
    - *L√∂sung:* Synonyme, Relevanzbewertung, Mehrwortbegriffe.
5. **Wie kann man die Ausgabe strukturieren?**
    - *L√∂sung:* Als Liste, JSON oder durch Kommas getrennt.
6. **Was ist ein Beispiel f√ºr ein Keyword mit mehreren W√∂rtern?**
    - *L√∂sung:* "K√ºnstliche Intelligenz"
7. **Wie kann man die Anzahl der Keywords begrenzen?**
    - *L√∂sung:* Durch Vorgabe im Prompt (z. B. "Nenne die 3 wichtigsten Keywords...").
8. **Wie kann man Keywords aus PDFs extrahieren?**
    - *L√∂sung:* Text extrahieren und dann LLM mit Keyword-Prompt nutzen.
9. **Was ist ein Nachteil automatischer Keyword-Extraktion?**
    - *L√∂sung:* Nicht immer perfekte Relevanz, Kontext kann fehlen.
10. **Wie kann man die Qualit√§t der Keywords verbessern?**
    - *L√∂sung:* Durch Nachbearbeitung, manuelle Kontrolle oder bessere Prompts.

---

## Einheit 5 ‚Äî Named Entity Recognition (NER)

### Umfangreiche Beschreibung & Grundlagen

Named Entity Recognition (NER) ist die Aufgabe, Eigennamen wie Personen, Orte und Organisationen in Texten automatisch zu erkennen. LLMs sind daf√ºr besonders geeignet, da sie viele Beispiele aus ihrem Training kennen und Kontext verstehen k√∂nnen.

**Warum ist NER wichtig?**

- Sie hilft, strukturierte Informationen aus unstrukturiertem Text zu gewinnen.
- Sie ist Grundlage f√ºr Suchmaschinen, Wissensdatenbanken, Chatbots und viele KI-Anwendungen.
- Sie erm√∂glicht die Verkn√ºpfung von Textdaten mit externen Datenquellen.

**Herausforderungen:**

- Unterschiedliche Schreibweisen und Abk√ºrzungen
- Mehrdeutigkeit (z. B. "Amazon" als Firma oder Fluss)
- Verschachtelte oder zusammengesetzte Entities

### 5 Beispiele f√ºr Named Entity Recognition (mit Python-Code)

1. **Einfache Entities:**

    Text:

    ```text
    "Barack Obama sprach 2015 in Berlin."
    ```

    Ergebnis:

    ```text
    Personen: ["Barack Obama"], Orte: ["Berlin"], Organisationen: []
    ```

    ```python
    # Datei: ner1_einfach.py
    from lib.helper_ollama import ollama

    text = "Barack Obama sprach 2015 in Berlin."
    prompt = f"Finde Named Entities (Personen, Orte, Organisationen) als JSON: {text}"
    result = ollama.generate(prompt)
    print("Entities:", result)
    ```

2. **Organisationen erkennen:**

    Text:

    ```text
    "Elon Musk gr√ºndete SpaceX in Kalifornien."
    ```

    Ergebnis:

    ```text
    Personen: ["Elon Musk"], Orte: ["Kalifornien"], Organisationen: ["SpaceX"]
    ```

    ```python
    # Datei: ner2_organisation.py
    from lib.helper_ollama import ollama

    text = "Elon Musk gr√ºndete SpaceX in Kalifornien."
    prompt = f"Finde Named Entities (Personen, Orte, Organisationen) als JSON: {text}"
    result = ollama.generate(prompt)
    print("Entities:", result)
    ```

3. **Mehrere S√§tze:**

    Text:

    ```text
    "Angela Merkel traf Emmanuel Macron in Paris. Microsoft investierte in OpenAI."
    ```

    Ergebnis:

    ```text
    Personen: ["Angela Merkel", "Emmanuel Macron"], Orte: ["Paris"], Organisationen: ["Microsoft", "OpenAI"]
    ```

    ```python
    # Datei: ner3_mehrere_saetze.py
    from lib.helper_ollama import ollama

    text = "Angela Merkel traf Emmanuel Macron in Paris. Microsoft investierte in OpenAI."
    prompt = f"Finde Named Entities (Personen, Orte, Organisationen) als JSON: {text}"
    result = ollama.generate(prompt)
    print("Entities:", result)
    ```

4. **Mehrdeutige Entities:**

    Text:

    ```text
    "Amazon expandiert nach Brasilien."
    ```

    Ergebnis:

    ```text
    Organisationen: ["Amazon"], Orte: ["Brasilien"]
    ```

    ```python
    # Datei: ner4_mehrdeutig.py
    from lib.helper_ollama import ollama

    text = "Amazon expandiert nach Brasilien."
    prompt = f"Finde Named Entities (Personen, Orte, Organisationen) als JSON: {text}"
    result = ollama.generate(prompt)
    print("Entities:", result)
    ```

5. **JSON-Ausgabe:**

    Text:

    ```text
    "Jeff Bezos gr√ºndete Amazon in Seattle."
    
    ```

    Ergebnis:

    ```text
    {"Personen": ["Jeff Bezos"], "Orte": ["Seattle"], "Organisationen": ["Amazon"]}
    ```

    ```python
    # Datei: ner5_json.py
    from lib.helper_ollama import ollama

    text = "Jeff Bezos gr√ºndete Amazon in Seattle."
    prompt = f"Extrahiere Named Entities im JSON-Format: {{'Personen': [], 'Orte': [], 'Organisationen': []}} Text: {text}"
    result = ollama.generate(prompt)
    print("Entities JSON:", result)
    ```

### 10 Fragen & L√∂sungen zu Named Entity Recognition

1. **Was ist Named Entity Recognition?**
    - *L√∂sung:* Das automatische Erkennen von Eigennamen (Personen, Orte, Organisationen) in Texten.
2. **Nenne drei Typen von Entities.**
    - *L√∂sung:* Personen, Orte, Organisationen.
3. **Warum ist NER f√ºr KI-Anwendungen wichtig?**
    - *L√∂sung:* Sie liefert strukturierte Informationen f√ºr Suche, Datenbanken, Chatbots etc.
4. **Was ist eine Herausforderung bei NER?**
    - *L√∂sung:* Mehrdeutigkeit, unterschiedliche Schreibweisen, verschachtelte Entities.
5. **Wie kann man die Ausgabe strukturieren?**
    - *L√∂sung:* Als Listen oder im JSON-Format.
6. **Wie kann man NER mit LLMs testen?**
    - *L√∂sung:* Durch gezielte Prompts und Vergleich der Ergebnisse.
7. **Was ist ein Beispiel f√ºr eine Organisation als Entity?**
    - *L√∂sung:* "Microsoft", "Amazon", "SpaceX"
8. **Wie kann man Entities aus mehreren S√§tzen extrahieren?**
    - *L√∂sung:* Text als Ganzes analysieren lassen, ggf. Listen ausgeben.
9. **Was ist ein Nachteil automatischer NER?**
    - *L√∂sung:* Fehler bei unbekannten Namen, Abk√ºrzungen oder Kontext.
10. **Wie kann man die Qualit√§t der NER-Ergebnisse verbessern?**
    - *L√∂sung:* Durch bessere Prompts, Nachbearbeitung oder Kombination mit anderen Tools.

---

## Einheit 6 ‚Äî FAQ-Bot mit Ollama

### Umfangreiche Beschreibung & Grundlagen

Ein FAQ-Bot (Frequently Asked Questions Bot) ist ein System, das h√§ufig gestellte Fragen automatisch beantwortet. Die Antworten basieren auf einer vorgegebenen FAQ-Liste oder einem Dokument. LLMs k√∂nnen solche Bots besonders flexibel machen, da sie auch √§hnliche oder umformulierte Fragen erkennen und beantworten k√∂nnen.

**Warum sind FAQ-Bots n√ºtzlich?**

- Sie entlasten Support-Teams und beantworten Standardfragen rund um die Uhr.
- Sie verbessern die Nutzererfahrung auf Webseiten und in Apps.
- Sie k√∂nnen mit neuen Fragen und Antworten einfach erweitert werden.

**Herausforderungen:**

- Fragen k√∂nnen unterschiedlich formuliert sein.
- Antworten m√ºssen pr√§zise und korrekt sein.
- Umgang mit Fragen, die nicht in der FAQ stehen.

### 5 Beispiele f√ºr FAQ-Bot-Anwendungen (mit Python-Code)

1. **Einfache FAQ als Text:**

    FAQ:

    ```text
    "Q: Was ist Python?\nA: Eine Programmiersprache."
    ```

    Frage:

    ```text
    "Was ist Python?"
    ```

    Ergebnis:

    ```text
    "Eine Programmiersprache."
    ```

    ```python
    # Datei: faq1_einfach.py
    from lib.helper_ollama import ollama

    faq = "Q: Was ist Python?\nA: Eine Programmiersprache."
    frage = "Was ist Python?"
    prompt = f"Beantworte die Frage basierend auf dieser FAQ:\n{faq}\n\nFrage: {frage}"
    result = ollama.generate(prompt)
    print("Antwort:", result)
    ```

2. **Frage umformuliert:**
    FAQ:

    ```text
    "Q: Was ist KI?\nA: Maschinen, die Aufgaben wie Menschen l√∂sen."
    ```

    Frage:

    ```text
    "Was versteht man unter K√ºnstlicher Intelligenz?"
    ````

    Ergebnis:

    ```text
    "Maschinen, die Aufgaben wie Menschen l√∂sen."
    ```

    ```python
    # Datei: faq2_umformuliert.py
    from lib.helper_ollama import ollama

    faq = "Q: Was ist KI?\nA: Maschinen, die Aufgaben wie Menschen l√∂sen."
    frage = "Was versteht man unter K√ºnstlicher Intelligenz?"
    prompt = f"Beantworte die Frage basierend auf dieser FAQ:\n{faq}\n\nFrage: {frage}"
    result = ollama.generate(prompt)
    print("Antwort:", result)
    ```

3. **Datei-Upload:**
    - FAQ wird aus einer hochgeladenen Datei geladen und durchsucht.
    - **Python-Code (Streamlit):**

    ```python
    # Datei: faq3_upload.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("FAQ-Bot mit Datei-Upload")
    file = st.file_uploader("FAQ hochladen", type="txt")
    frage = st.text_input("Stelle eine Frage:")
    if file and frage:
        faq = file.read().decode()
        prompt = f"Beantworte die Frage basierend auf dieser FAQ:\n{faq}\n\nFrage: {frage}"
        if st.button("Antworten"):
            result = ollama.generate(prompt)
            st.write("Antwort:", result)
    ```

4. **Mehrere FAQ-Dateien kombinieren:**
    - Mehrere Dokumente werden zusammengef√ºhrt, um den Wissensstand zu erweitern.
    - **Python-Code (Streamlit):**

    ```python
    # Datei: faq4_mehrere_uploads.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("FAQ-Bot mit mehreren Dateien")
    files = st.file_uploader("Mehrere FAQs hochladen", type="txt", accept_multiple_files=True)
    frage = st.text_input("Stelle eine Frage:")
    if files and frage:
        faq_data = "\n".join([f.read().decode() for f in files])
        prompt = f"Beantworte die Frage basierend auf dieser FAQ:\n{faq_data}\n\nFrage: {frage}"
        if st.button("Antworten"):
            result = ollama.generate(prompt)
            st.write("Antwort:", result)
    ```

5. **Umgang mit unbekannten Fragen:**

    Frage:

    ```text
    "Wie funktioniert Quantencomputing?" (nicht in FAQ)
    ```

    Ergebnis:

    ```text
    "Diese Frage ist leider nicht in der FAQ enthalten."
    ```

    ```python
    # Datei: faq5_unbekannt.py
    from lib.helper_ollama import ollama

    faq = "Q: Was ist Python?\nA: Eine Programmiersprache."
    frage = "Wie funktioniert Quantencomputing?"
    prompt = f"Beantworte die Frage basierend auf dieser FAQ. Wenn die Antwort nicht enthalten ist, sage: 'Diese Frage ist leider nicht in der FAQ enthalten.'\n{faq}\n\nFrage: {frage}"
    result = ollama.generate(prompt)
    print("Antwort:", result)
    ```

### 10 Fragen & L√∂sungen zu FAQ-Bots

1. **Was ist ein FAQ-Bot?**
    - *L√∂sung:* Ein System, das h√§ufig gestellte Fragen automatisch beantwortet.
2. **Wie kann ein FAQ-Bot erweitert werden?**
    - *L√∂sung:* Durch Hinzuf√ºgen neuer Fragen und Antworten zur FAQ-Liste.
3. **Was ist eine Herausforderung bei FAQ-Bots?**
    - *L√∂sung:* Unterschiedliche Formulierungen der Fragen.
4. **Wie kann man einen FAQ-Bot mit LLMs bauen?**
    - *L√∂sung:* FAQ als Kontext in den Prompt geben und die Frage anh√§ngen.
5. **Wie kann man mehrere FAQ-Dateien nutzen?**
    - *L√∂sung:* Dateien zusammenf√ºhren und als Kontext verwenden.
6. **Wie sollte der Bot reagieren, wenn eine Frage nicht in der FAQ steht?**
    - *L√∂sung:* Freundlich darauf hinweisen, dass die Antwort nicht bekannt ist.
7. **Was ist ein Vorteil von LLM-basierten FAQ-Bots?**
    - *L√∂sung:* Sie erkennen auch umformulierte oder √§hnliche Fragen.
8. **Wie kann man die Qualit√§t der Antworten sichern?**
    - *L√∂sung:* FAQ regelm√§√üig pr√ºfen und aktualisieren.
9. **Wie kann man einen FAQ-Bot in eine App integrieren?**
    - *L√∂sung:* Mit Streamlit, Web-Frameworks oder Chatbots.
10. **Was ist ein Nachteil von FAQ-Bots?**
    - *L√∂sung:* Sie k√∂nnen keine komplexen, individuellen Probleme l√∂sen.

---

## Einheit 7 ‚Äî Kombination von Analysen (Sentiment + Keywords + Entities)

### Umfangreiche Beschreibung & Grundlagen

LLMs sind in der Lage, mehrere Analyseaufgaben in einem Schritt zu erledigen. Das bedeutet, man kann mit einem einzigen Prompt gleichzeitig die Stimmung, Schl√ºsselw√∂rter, Named Entities und sogar Zusammenfassungen aus einem Text extrahieren lassen. Das spart Zeit und erm√∂glicht komplexe Auswertungen mit wenig Code.

**Warum ist die Kombination von Analysen n√ºtzlich?**

- Sie liefert ein umfassendes Bild eines Textes auf einen Blick.
- Sie spart Rechenzeit und vereinfacht Workflows.
- Sie ist ideal f√ºr Dashboards, Monitoring und automatisierte Reports.

**Herausforderungen:**

- Die Formatierung der Ausgabe muss klar vorgegeben werden.
- Die Ergebnisse m√ºssen ggf. nachbearbeitet oder geparst werden.
- Bei sehr langen Texten kann das Kontextfenster des Modells √ºberschritten werden.

### 5 Beispiele f√ºr kombinierte Analysen (mit Python-Code)

1. **Stimmung + Keywords:**

    Text:

    ```text
    "Das neue iPhone ist beeindruckend, aber sehr teuer."
    ```

    Ergebnis:

    ```text
    Stimmung: "Gemischt", Keywords: ["iPhone", "teuer"]
    ```

    ```python
    # Datei: kombi1_stimmung_keywords.py
    from lib.helper_ollama import ollama

    text = "Das neue iPhone ist beeindruckend, aber sehr teuer."
    prompt = f"Analysiere diesen Text und gib zur√ºck:\n1. Stimmung (Positiv/Negativ/Neutral/Gemischt)\n2. Keywords als Liste\nText: {text}"
    result = ollama.generate(prompt)
    print("Analyse:", result)
    ```

2. **Alles in einem:**

    Text:

    ```text
    "Angela Merkel hielt in Berlin eine Rede √ºber die EU."
    ```

    Ergebnis:

    ```text
    Stimmung, Keywords, Named Entities, Zusammenfassung
    ```

    ```python
    # Datei: kombi2_alles.py
    from lib.helper_ollama import ollama

    text = "Angela Merkel hielt in Berlin eine Rede √ºber die EU."
    prompt = f"Analysiere den Text und gib zur√ºck:\n- Stimmung\n- Keywords\n- Named Entities\n- Kurze Zusammenfassung\nText: {text}"
    result = ollama.generate(prompt)
    print("Analyse:", result)
    ```

3. **JSON-Ausgabe:**

    Prompt:

    ```prompt
    "Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities."
    ```

    ```python
    # Datei: kombi3_json.py
    from lib.helper_ollama import ollama

    text = "Tesla investiert in KI und baut neue Fabriken."
    prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities. Text: {text}"
    result = ollama.generate(prompt)
    print("JSON-Analyse:", result)
    ```

4. **Mehrere Texte analysieren:**
    - Liste von Texten wird in einer Schleife analysiert
    - Ergebnisse werden gesammelt.

    ```python
    # Datei: kombi4_mehrere.py
    from lib.helper_ollama import ollama

    texte = [
        "Das neue iPhone ist beeindruckend, aber sehr teuer.",
        "Angela Merkel hielt in Berlin eine Rede √ºber die EU.",
        "Tesla investiert in KI und baut neue Fabriken."
    ]
    for text in texte:
        prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities. Text: {text}"
        result = ollama.generate(prompt)
        print(f"Text: {text}\nAnalyse: {result}\n")
    ```

5. **Dashboard-Anwendung:**
    - Ein Streamlit-Dashboard zeigt f√ºr jeden Text alle Analyse-Ergebnisse √ºbersichtlich an.

    ```python
    # Datei: kombi5_dashboard.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("Kombinierte Textanalyse")
    text = st.text_area("Text eingeben")
    if st.button("Analysieren") and text:
        prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
        result = ollama.generate(prompt)
        st.write("Analyse:", result)
    ```

### 10 Fragen & L√∂sungen zu kombinierten Analysen

1. **Was bedeutet kombinierte Analyse bei LLMs?**
    - *L√∂sung:* Mehrere Analyseaufgaben (z. B. Stimmung, Keywords, Entities) werden in einem Schritt erledigt.
2. **Was ist ein Vorteil kombinierter Analysen?**
    - *L√∂sung:* Spart Zeit, liefert umfassende Ergebnisse.
3. **Wie kann man die Ausgabe strukturieren?**
    - *L√∂sung:* Durch klare Vorgaben im Prompt, z. B. Listen oder JSON.
4. **Was ist ein Nachteil bei sehr langen Texten?**
    - *L√∂sung:* Das Kontextfenster des Modells kann √ºberschritten werden.
5. **Wie kann man kombinierte Analysen in einer App nutzen?**
    - *L√∂sung:* In Dashboards, Monitoring-Tools, Reports.
6. **Wie kann man die Ergebnisse weiterverarbeiten?**
    - *L√∂sung:* Durch Parsen der Ausgabe (z. B. JSON in Python).
7. **Was ist ein Beispiel f√ºr eine kombinierte Analyse?**
    - *L√∂sung:* Stimmung, Keywords und Entities aus einem Text extrahieren.
8. **Wie kann man mehrere Texte automatisch analysieren?**
    - *L√∂sung:* Mit einer Schleife und einer Analysefunktion.
9. **Wie kann man die Qualit√§t der kombinierten Analyse verbessern?**
    - *L√∂sung:* Durch pr√§zise Prompts und Formatvorgaben.
10. **Was ist ein typischer Fehler bei kombinierten Analysen?**
    - *L√∂sung:* Unklare Formatvorgaben, zu lange Texte, fehlende Nachbearbeitung.

---

## Einheit 8 ‚Äî Erweiterte Streamlit-App: Analyse-Dashboard

### Umfangreiche Beschreibung & Grundlagen

Ein Analyse-Dashboard ist eine interaktive App, die verschiedene Textanalyse-Funktionen in einer √ºbersichtlichen Oberfl√§che vereint. Mit Streamlit kann man schnell und einfach ein Dashboard bauen, das Sentimentanalyse, Keyword-Extraktion, Named Entity Recognition und Zusammenfassung kombiniert. Nutzer k√∂nnen Texte eingeben, hochladen oder aus einer Liste ausw√§hlen und erhalten sofort eine umfassende Analyse.

**Warum sind Dashboards n√ºtzlich?**

- Sie machen komplexe Analysen f√ºr alle zug√§nglich.
- Sie erm√∂glichen schnelle Auswertungen ohne Programmierkenntnisse.
- Sie sind ideal f√ºr Pr√§sentationen, Monitoring und Prototyping.

**Herausforderungen:**

- √úbersichtliche Darstellung der Ergebnisse
- Performance bei gro√üen Textmengen
- Flexibilit√§t f√ºr verschiedene Analysearten

### 5 Beispiele f√ºr Analyse-Dashboards (mit Python-Code)

1. **Einfaches Textfeld:**

    Nutzer gibt einen Text ein, Dashboard zeigt alle Analysen an.

    ```python
    # Datei: dashboard1_textfeld.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("Textanalyse Dashboard")
    text = st.text_area("Text eingeben")
    if st.button("Analysieren") and text:
        prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
        result = ollama.generate(prompt)
        st.write("Analyse:", result)
    ```

2. **Datei-Upload:**

    Nutzer l√§dt ein PDF oder eine Textdatei hoch, Dashboard analysiert den gesamten Inhalt.

    ```python
    # Datei: dashboard2_upload.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("Datei-Upload Analyse")
    file = st.file_uploader("Textdatei hochladen", type=["txt"])
    if file:
        text = file.read().decode()
        if st.button("Analysieren"):
            prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
            result = ollama.generate(prompt)
            st.write("Analyse:", result)
    ```

3. **Mehrere Texte vergleichen:**

    Dashboard zeigt Analyse-Ergebnisse f√ºr mehrere Texte nebeneinander.

    ```python
    # Datei: dashboard3_vergleich.py
    import streamlit as st
    from lib.helper_ollama import ollama

    st.title("Vergleich mehrerer Texte")
    texte = st.text_area("Texte (jeweils durch Zeilenumbruch trennen)")
    if st.button("Analysieren") and texte:
        text_list = [t for t in texte.split("\n") if t.strip()]
        cols = st.columns(len(text_list))
        for i, text in enumerate(text_list):
            prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
            result = ollama.generate(prompt)
            with cols[i]:
                st.write(f"**Text {i+1}:**", text)
                st.write(result)
    ```

4. **Ergebnisse als Tabelle:**
    - Alle Analysen werden in einer Tabelle oder als JSON angezeigt.
    - **Python-Code (Streamlit + pandas):**

    ```python
    # Datei: dashboard4_tabelle.py
    import streamlit as st
    import pandas as pd
    from lib.helper_ollama import ollama

    st.title("Analyse als Tabelle")
    texte = st.text_area("Texte (je Zeile ein Text)")
    if st.button("Analysieren") and texte:
        text_list = [t for t in texte.split("\n") if t.strip()]
        daten = []
        for text in text_list:
            prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
            result = ollama.generate(prompt)
            daten.append({"Text": text, "Analyse": result})
        df = pd.DataFrame(daten)
        st.dataframe(df)
    ```

5. **Export-Funktion:**

    Ergebnisse k√∂nnen als CSV oder PDF exportiert werden.

    ```python
    # Datei: dashboard5_export.py
    import streamlit as st
    import pandas as pd
    from lib.helper_ollama import ollama

    st.title("Analyse mit Export")
    texte = st.text_area("Texte (je Zeile ein Text)")
    if st.button("Analysieren") and texte:
        text_list = [t for t in texte.split("\n") if t.strip()]
        daten = []
        for text in text_list:
            prompt = f"Analysiere den Text und gib das Ergebnis als JSON zur√ºck: Stimmung, Keywords, Entities, Zusammenfassung. Text: {text}"
            result = ollama.generate(prompt)
            daten.append({"Text": text, "Analyse": result})
        df = pd.DataFrame(daten)
        st.dataframe(df)
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("CSV herunterladen", csv, "analysen.csv", "text/csv")
    ```

### 10 Fragen & L√∂sungen zu Analyse-Dashboards

1. **Was ist ein Analyse-Dashboard?**
    - *L√∂sung:* Eine App, die verschiedene Analysefunktionen in einer Oberfl√§che vereint.
2. **Wie kann man ein Dashboard mit Streamlit bauen?**
    - *L√∂sung:* Mit Python und der Streamlit-Bibliothek.
3. **Welche Analysefunktionen kann ein Dashboard enthalten?**
    - *L√∂sung:* Sentiment, Keywords, NER, Zusammenfassung, u. v. m.
4. **Was ist ein Vorteil von Dashboards?**
    - *L√∂sung:* Sie machen Analysen f√ºr alle zug√§nglich und einfach bedienbar.
5. **Wie kann man mehrere Texte vergleichen?**
    - *L√∂sung:* Durch Anzeige der Ergebnisse nebeneinander oder in einer Tabelle.
6. **Wie kann man Ergebnisse exportieren?**
    - *L√∂sung:* Als CSV, PDF oder durch Kopieren der Daten.
7. **Was ist eine Herausforderung bei gro√üen Textmengen?**
    - *L√∂sung:* Performance und √úbersichtlichkeit.
8. **Wie kann man die Nutzerfreundlichkeit erh√∂hen?**
    - *L√∂sung:* Klare Struktur, einfache Bedienung, gute Visualisierung.
9. **Wie kann man das Dashboard erweitern?**
    - *L√∂sung:* Weitere Analysefunktionen, Filter, Visualisierungen hinzuf√ºgen.
10. **Was ist ein typischer Fehler bei Dashboards?**
    - *L√∂sung:* Un√ºbersichtliche Darstellung, fehlende Export- oder Vergleichsfunktionen.

---

## Einheit 9 - Zusammenfassung

Nach Tag 3 k√∂nnen die Studierenden:

- Texte mit Ollama analysieren (Stimmung, Themen, Keywords, Entities)
- einen FAQ-Bot mit Dokumenten erstellen
- mehrere Analysen kombinieren
- ein eigenes Analyse-Dashboard in Streamlit bauen
- die Grenzen solcher Modelle erkennen (Halluzinationen, Mehrdeutigkeit)

---

## Einheit 10 - Mini-Projekte

### Mini-Projekt 1: Intelligenter PDF-Analyzer

**Aufgabe:** Baue eine App, die PDF-Dokumente hochl√§dt und mit KI analysiert.

**L√∂sung:**

```python
import streamlit as st
import PyPDF2
import io
from lib.helper_ollama import ollama

st.title("PDF-Analyzer mit KI")
pdf_file = st.file_uploader("PDF hochladen", type="pdf")

if pdf_file:
    # PDF Text extrahieren
    pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    
    st.write(f"Extrahierter Text ({len(text)} Zeichen)")
    
    analyse_typ = st.selectbox("Analyse-Typ:", 
                              ["Zusammenfassung", "Hauptthemen", "Sentiment", "Schl√ºsselw√∂rter"])
    
    if st.button("Analysieren"):
        if analyse_typ == "Zusammenfassung":
            prompt = f"Fasse den folgenden Text in 5 S√§tzen zusammen:\n{text[:2000]}"
        elif analyse_typ == "Hauptthemen":
            prompt = f"Identifiziere die 5 Hauptthemen in diesem Text:\n{text[:2000]}"
        elif analyse_typ == "Sentiment":
            prompt = f"Analysiere die Stimmung dieses Textes (positiv/neutral/negativ):\n{text[:2000]}"
        else:
            prompt = f"Extrahiere die 10 wichtigsten Schl√ºsselw√∂rter:\n{text[:2000]}"
        
        result = ollama.generate(prompt)
        st.write("**Ergebnis:**", result)
```

### Mini-Projekt 2: Multi-Language Content Analyzer

**Aufgabe:** Analysiere Texte in verschiedenen Sprachen und √ºbersetze sie.

**L√∂sung:**

```python
import streamlit as st
from lib.helper_ollama import ollama

st.title("Multi-Language Content Analyzer")
text = st.text_area("Text eingeben (beliebige Sprache)")

if text:
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Spracherkennung & Analyse")
        if st.button("Analysieren"):
            prompt = f"""Analysiere den folgenden Text:
1. Erkenne die Sprache
2. Bestimme die Stimmung
3. Extrahiere Hauptthemen
4. Gib eine kurze Zusammenfassung

Text: {text}"""
            result = ollama.generate(prompt)
            st.write(result)
    
    with col2:
        st.subheader("√úbersetzung")
        ziel_sprache = st.selectbox("√úbersetzen zu:", 
                                   ["Deutsch", "Englisch", "Franz√∂sisch", "Spanisch"])
        if st.button("√úbersetzen"):
            prompt = f"√úbersetze den folgenden Text zu {ziel_sprache}:\n{text}"
            result = ollama.generate(prompt)
            st.write(result)
```

### Mini-Projekt 3: Social Media Content Optimizer

**Aufgabe:** Optimiere Texte f√ºr verschiedene Social Media Plattformen.

**L√∂sung:**

```python
import streamlit as st
from lib.helper_ollama import ollama

st.title("Social Media Content Optimizer")
original_text = st.text_area("Urspr√ºnglicher Text")
plattform = st.selectbox("Ziel-Plattform:", 
                        ["Twitter", "LinkedIn", "Instagram", "Facebook"])

if st.button("Optimieren") and original_text:
    if plattform == "Twitter":
        prompt = f"K√ºrze den Text auf max. 280 Zeichen f√ºr Twitter, behalte die Kernbotschaft:\n{original_text}"
    elif plattform == "LinkedIn":
        prompt = f"Schreibe den Text professioneller und strukturierter f√ºr LinkedIn um:\n{original_text}"
    elif plattform == "Instagram":
        prompt = f"Mache den Text emotionaler und visueller f√ºr Instagram:\n{original_text}"
    else:
        prompt = f"Mache den Text einladender und community-orientiert f√ºr Facebook:\n{original_text}"
    
    result = ollama.generate(prompt)
    st.write("**Optimierter Text:**")
    st.write(result)
    
    # Zus√§tzlich: Hashtag-Vorschl√§ge
    if st.button("Hashtags vorschlagen"):
        hashtag_prompt = f"Schlage 5 relevante Hashtags f√ºr diesen {plattform}-Post vor:\n{result}"
        hashtags = ollama.generate(hashtag_prompt)
        st.write("**Hashtag-Vorschl√§ge:**", hashtags)
```

### Mini-Projekt 4: Competitive Content Analysis

**Aufgabe:** Vergleiche Inhalte von Konkurrenten und analysiere deren Strategien.

**L√∂sung:**

```python
import streamlit as st
import pandas as pd
from lib.helper_ollama import ollama

st.title("Competitive Content Analysis")
st.write("Analysiere Inhalte von bis zu 3 Konkurrenten")

konkurrenten = []
for i in range(3):
    name = st.text_input(f"Konkurrent {i+1} Name:")
    content = st.text_area(f"Content von {name if name else f'Konkurrent {i+1}'}:")
    if name and content:
        konkurrenten.append({"Name": name, "Content": content})

if st.button("Analysieren") and konkurrenten:
    ergebnisse = []
    
    for k in konkurrenten:
        prompt = f"""Analysiere den folgenden Marketing-Content:
1. Hauptbotschaft
2. Zielgruppe
3. Tonalit√§t/Stil
4. St√§rken
5. Verbesserungsvorschl√§ge

Content: {k['Content']}"""
        
        analyse = ollama.generate(prompt)
        ergebnisse.append({
            "Konkurrent": k["Name"],
            "Analyse": analyse
        })
    
    # Vergleichstabelle
    df = pd.DataFrame(ergebnisse)
    st.dataframe(df)
    
    # Strategische Empfehlungen
    if st.button("Strategische Empfehlungen"):
        alle_analysen = "\n\n".join([f"{e['Konkurrent']}: {e['Analyse']}" for e in ergebnisse])
        strategie_prompt = f"Basierend auf diesen Konkurrenzanalysen, gib strategische Empfehlungen f√ºr die eigene Content-Strategie:\n{alle_analysen}"
        empfehlungen = ollama.generate(strategie_prompt)
        st.write("**Strategische Empfehlungen:**", empfehlungen)
```

### Mini-Projekt 5: Real-time Content Monitoring Dashboard

**Aufgabe:** √úberwache und analysiere Inhalte in Echtzeit.

**L√∂sung:**

```python
import streamlit as st
import pandas as pd
import time
from datetime import datetime
from lib.helper_ollama import ollama

st.title("Real-time Content Monitoring")

# Initialisiere Session State
if 'monitoring_data' not in st.session_state:
    st.session_state.monitoring_data = []

# Input f√ºr neuen Content
new_content = st.text_area("Neuen Content hinzuf√ºgen:")
source = st.text_input("Quelle (z.B. Website, Social Media):")

if st.button("Content analysieren") and new_content:
    # Analysiere Content
    prompt = f"""Analysiere diesen Content schnell:
- Sentiment (1-10)
- Kategorie (News/Marketing/Info/etc.)
- Dringlichkeit (niedrig/mittel/hoch)
- Keywords (top 3)

Content: {new_content}"""
    
    analyse = ollama.generate(prompt)
    
    # Speichere in Session State
    st.session_state.monitoring_data.append({
        "Timestamp": datetime.now().strftime("%H:%M:%S"),
        "Source": source,
        "Content": new_content[:100] + "..." if len(new_content) > 100 else new_content,
        "Analyse": analyse
    })

# Dashboard anzeigen
if st.session_state.monitoring_data:
    st.subheader("Live Dashboard")
    df = pd.DataFrame(st.session_state.monitoring_data)
    st.dataframe(df)
    
    # Statistiken
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Gesamt Inhalte", len(st.session_state.monitoring_data))
    with col2:
        st.metric("Letzte Aktualisierung", df.iloc[-1]["Timestamp"])
    with col3:
        if st.button("Dashboard leeren"):
            st.session_state.monitoring_data = []
            st.experimental_rerun()
```

---

> **Ausblick:**  
> Soll f√ºr Tag 4 (Fortgeschrittene Anwendungen: Datenintegration mit Pandas, Q&A √ºber CSV-Dateien, KI-Dashboards, Deployment) auch ein vollst√§ndiges Lehrbuch-Kapitel mit vielen Beispielen erstellt werden?
