# рджрд┐рд╡рд╕ 4 - рдПрд▓рдПрд▓рдПрдо рдЖрдгрд┐ рдбреЗрдЯрд╛рд╕рд╣ рдкреНрд░рдЧрдд рдЕрдиреБрдкреНрд░рдпреЛрдЧ

## ЁЯУЕ тАЛтАЛрд╡реЗрд│рд╛рдкрддреНрд░рдХ 09:00 - 15:00

### рд╡рд┐рд╣рдВрдЧрд╛рд╡рд▓реЛрдХрди

рджрд┐рд╡рд╕ рдПрд▓рдПрд▓рдПрдо рдЖрдгрд┐ рдбреЗрдЯрд╛ рдПрдХрддреНрд░реАрдХрд░рдгрд╛рд╕рд╣ рдкреНрд░рдЧрдд рдЕрдиреБрдкреНрд░рдпреЛрдЧрд╛рдВрдордзреНрдпреЗ рдкреНрд░рд╡реЗрд╢ рдХрд░рддреЛ. рдкреНрд░рддреНрдпреЗрдХ рдпреБрдирд┐рдЯрдордзреНрдпреЗ рд▓рд╣рд╛рди рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг, рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЙрджрд╛рд╣рд░рдгреЗ рдЖрдгрд┐ рд╡реНрдпрд╛рдпрд╛рдо рдЕрд╕рддрд╛рдд.

-

### рд╡реЗрд│рд╛рдкрддреНрд░рдХ

| рд╡реЗрд│ | рдпреБрдирд┐рдЯ / рд╕рд╛рдордЧреНрд░реА | рдХрд╛рд▓рд╛рд╡рдзреА |
| ----------------- | ----------------------------------------------------------------------------------------------------------------------------------------
| ** 09: 00 - 09: 20 ** | рдкрд░рд┐рдЪрдп рдЖрдгрд┐ рд╡рд┐рд╣рдВрдЧрд╛рд╡рд▓реЛрдХрди - рдкреНрд░реЗрд░рдгрд╛, рджрд┐рд╡рд╕рд╛рдЪреА рдЙрджреНрджреАрд╖реНрдЯреЗ | 20 рдорд┐рдирд┐рдЯреЗ |
| ** 09: 20 - 10: 05 ** | ** рдпреБрдирд┐рдЯ 1.рез: ** рдкрд╛рдВрдбрд╛рд╕рд╣ рдбреЗрдЯрд╛ рдПрдХрддреНрд░реАрдХрд░рдг - рд╕реАрдПрд╕рд╡реНрд╣реА/рдПрдХреНрд╕реЗрд▓ рд▓реЛрдбрд┐рдВрдЧ, рдлрд┐рд▓реНрдЯрд░рд┐рдВрдЧ, рдПрд▓рдПрд▓рдПрдо рдПрдХрддреНрд░реАрдХрд░рдг | 45 рдорд┐рдирд┐рдЯреЗ |
| ** 10: 05 - 10: 35 ** | ** рдпреБрдирд┐рдЯ 2.реи: ** рд╕реАрдПрд╕рд╡реНрд╣реА рдлрд╛рдпрд▓реАрдВрдмрджреНрджрд▓ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░ - рдХреНрд╡реЗрд░реА, рдПрд▓рдПрд▓рдПрдо рдЙрддреНрддрд░реЗ, рдкреНрд░рд╡рд╛рд╣ рдЕтАНреЕрдк | 30 рдорд┐рдирд┐рдЯреЗ |
| ** 10: 35 - 11: 15 ** | ** рдпреБрдирд┐рдЯ 3.3: ** рдкреНрд░рд╡рд╛рд╣рд╛рд╕рд╣ рдПрдЖрдп рдбреЕрд╢рдмреЛрд░реНрдбреНрд╕ - рдЪрд╛рд░реНрдЯ, рдПрд▓рдПрд▓рдПрдо рдЯрд┐рдкреНрдкрдгреНрдпрд╛, рдЧрдЯ рддреБрд▓рдирд╛ | 40 рдорд┐рдирд┐рдЯреЗ |
| ** 11: 15 - 11: 30 ** | тШХ ** рдмреНрд░реЗрдХ ** | 15 рдорд┐рдирд┐рдЯреЗ |
| ** 11: 30 - 12: 10 ** | ** рдпреБрдирд┐рдЯ 4.4: ** рдЙрдкрдпреЛрдЬрди - рдЕреЕрдк, рдЖрд╡рд╢реНрдпрдХрддрд╛. 40 рдорд┐рдирд┐рдЯреЗ |
| ** 12: 10 - 12: 40 ** | ** рдпреБрдирд┐рдЯ 4.5. :: ** рдмреЛрдирд╕: рдПрдХрд╛рдзрд┐рдХ рдбреЗрдЯрд╛ рд╕реНрд░реЛрддрд╛рдВрдордзреНрдпреЗ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░ - рд╕реАрдПрд╕рд╡реНрд╣реА + рд╕рд╛рдорд╛рдиреНрдп рдкреНрд░рд╢реНрди/рдордЬрдХреВрд░, рдПрдХрддреНрд░рд┐рдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг | 30 рдорд┐рдирд┐рдЯреЗ |
| ** 12: 40 - 1:10 рджреБрдкрд╛рд░реА ** | рд╡реНрдпрд╛рдпрд╛рдо рдЖрдгрд┐ рд╕рд░рд╛рд╡ - рд╕реНрд╡рддрдГрдЪрд╛ рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд, рдорд┐рдиреА -рдкреНрд░реЛрдЬреЗрдХреНрдЯ рдкреНрд░рд╛рд░рдВрдн рдХрд░рд╛ | 30 рдорд┐рдирд┐рдЯреЗ |
| ** 13: 10 - 14: 10 ** | ЁЯН╜ ** рд▓рдВрдЪ рдмреНрд░реЗрдХ ** | 60 рдорд┐рдирд┐рдЯреЗ |
| ** 14: 10 - 14: 40 ** | рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк рдЖрдгрд┐ рд╕рд╛рджрд░реАрдХрд░рдг - рдПрдХрд╛рдзрд┐рдХ рдбреЗрдЯрд╛ рд╕реНрд░реЛрддрд╛рдВрд╕рд╣ рдЕреЕрдк, рдкреНрд░рд╢реНрдиреЛрддреНрддрд░, рдбреЕрд╢рдмреЛрд░реНрдб | 30 рдорд┐рдирд┐рдЯреЗ |
| ** 14: 40 - 15: 00 ** | рд╕рд╛рд░рд╛рдВрд╢ рдЖрдгрд┐ рджреГрд╖реНрдЯреАрдХреЛрди - рдкреНрд░рддрд┐рдмрд┐рдВрдм, рдкреБрдвреАрд▓ рдЪрд░рдг | 20 рдорд┐рдирд┐рдЯреЗ |

-

## рдпреБрдирд┐рдЯ рдПрдХреНрд╕рдкрд╛рдпрд░реА

- ** рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг: ** рдЕрдВрджрд╛рдЬреЗ. 10-15 рдорд┐
- ** рдЙрджрд╛рд╣рд░рдгреЗ: ** рдЕрдВрджрд╛рдЬреЗ. 10 рдорд┐
- ** рд╡реНрдпрд╛рдпрд╛рдо: ** рдЕрдВрджрд╛рдЬреЗ. 15-20 рдорд┐  
    Ex рд╡реНрдпрд╛рдпрд╛рдо рдереЗрдЯ рдЬреНрдпреБрдкрд┐рдЯрд░, рд╡рд┐ рдХреЛрдб рдХрд┐рдВрд╡рд╛ рдкреНрд░рд╡рд╛рд╣рд╛рдордзреНрдпреЗ рдХреЗрд▓рд╛ рдЬрд╛рддреЛ.

-

## рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк (2:10 p.m. - 2:40 p.m.)

рджрд┐рд╡рд╕рд╛рдЪреНрдпрд╛ рд╢реЗрд╡рдЯреА, рдПрдХ рдЕреЕрдк рд╡рд┐рдХрд╕рд┐рдд рдХреЗрд▓рд╛ рдЬрд╛рддреЛ рдЬреЛ рдЦрд╛рд▓реАрд▓ рд╡реИрд╢рд┐рд╖реНрдЯреНрдпреЗ рдПрдХрддреНрд░рд┐рдд рдХрд░рддреЛ:

- ** рд╕реАрдПрд╕рд╡реНрд╣реА рдЕрдкрд▓реЛрдб **
- ** FAQ/рдордЬрдХреВрд░ рдЕрдкрд▓реЛрдб **
- ** рдкреНрд░рдХреНрд░рд┐рдпрд╛: ** рдкрд╛рдВрдбрд╛рд╕ рдЖрдгрд┐ рдПрд▓рдПрд▓рдПрдорд╕рд╣ рдбреЗрдЯрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг
- ** рдбреЕрд╢рдмреЛрд░реНрдб: ** рдЪрд╛рд░реНрдЯ, рдПрдЖрдп рдЯрд┐рдкреНрдкрдгреНрдпрд╛
- ** рдкреНрд░рд╢реНрдиреЛрддреНрддрд░: ** рдПрдХрддреНрд░рд┐рдд рдбреЗрдЯрд╛ рд╕реНрд░реЛрддрд╛рдВрдмрджреНрджрд▓рдЪреЗ рдкреНрд░рд╢реНрди

-

## рдпреБрдирд┐рдЯ 1 - рдкрд╛рдВрдбрд╛рд╕рд╣ рдбреЗрдЯрд╛ рдПрдХрддреНрд░реАрдХрд░рдг

### рдЙрджрд╛рд╣рд░рдгреЗ

#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реАрдПрд╕рд╡реНрд╣реА рд▓реЛрдб рдХрд░рд╛

```python
import pandas as pd
df = pd.read_csv("sales.csv")
print(df.head())
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд▓реЛрдб рдПрдХреНрд╕реЗрд▓

```python
df = pd.read_excel("data.xlsx")
print(df.shape)
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдлрд┐рд▓реНрдЯрд░рд┐рдВрдЧ

```python
kunden = df[df["Country"] == "Germany"]
print(kunden)
```
#### рдЙрджрд╛рд╣рд░рдг 4 - рдПрд▓рдПрд▓рдПрдо рдПрдХрддреНрд░реАрдХрд░рдг

```python
import requests
stats = df.describe().to_string()
prompt = f"Analysiere die Verkaufsdaten:\n{stats}"
r = requests.post("http://localhost:11434/api/generate",
                  json={"model": "llama2", "prompt": prompt})
print(r.json()["response"])
```
#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реАрдПрд╕рд╡реНрд╣реА рд▓реЛрдб рдХрд░рд╛

```python
# Datei: einheit41_csv_laden.py
import pandas as pd
df = pd.read_csv("sales.csv")
print(df.head())
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд▓реЛрдб рдПрдХреНрд╕реЗрд▓

```python
# Datei: einheit41_excel_laden.py
import pandas as pd
df = pd.read_excel("data.xlsx")
print(df.shape)
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдлрд┐рд▓реНрдЯрд░рд┐рдВрдЧ

```python
# Datei: einheit41_filterung.py
import pandas as pd
df = pd.read_csv("sales.csv")
kunden = df[df["Country"] == "Germany"]
print(kunden)
```
#### рдЙрджрд╛рд╣рд░рдг 4 - рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗрд╕рд╣ рдПрд▓рдПрд▓рдПрдо рдПрдХрддреНрд░реАрдХрд░рдг

```python
# Datei: einheit41_llm_integration.py
import pandas as pd
from lib.helper_ollama import ollama

df = pd.read_csv("sales.csv")
stats = df.describe().to_string()
prompt = f"Analysiere die Verkaufsdaten:\n{stats}"
result = ollama.generate(prompt)
print(result)
```
### рд╡реНрдпрд╛рдпрд╛рдо

- рд╕реНрддрдВрднрд╛рдВрдЪреЗ рдирд╛рд╡, рд╡рдп, рдЙрддреНрдкрдиреНрдирд╛рд╕рд╣ рд╕реАрдПрд╕рд╡реНрд╣реА рд▓реЛрдб рдХрд░рд╛. рдордзреНрдпрдо рдЙрддреНрдкрдиреНрдирд╛рдЪреА рдЧрдгрдирд╛ рдХрд░рд╛.
- 40 рд╡рд░реНрд╖рд╛рдВрдкреЗрдХреНрд╖рд╛ рдЬрд╛рд╕реНрдд рд╡рдпрд╛рдЪреНрдпрд╛ рд╕рд░реНрд╡ рдЧреНрд░рд╛рд╣рдХрд╛рдВрдирд╛ рдлрд┐рд▓реНрдЯрд░ рдХрд░рд╛.
- рдЖрдХрдбреЗрд╡рд╛рд░реА рдУрд▓реНрд▓рд╛рдорд╛рд▓рд╛ рдкрд╛рдард╡рд╛ рдЖрдгрд┐ рдЖрд░реНрдерд┐рдХ рд╡реНрдпрд╛рдЦреНрдпрд╛ рд╡рд┐рдЪрд╛рд░рд╛.
- рдЙрддреНрдкрдиреНрдирд╛рджреНрд╡рд╛рд░реЗ рдЦрд╛рд▓реА рдЙрддрд░рддреНрдпрд╛ рдСрд░реНрдбрд░рдордзреНрдпреЗ рдЧреНрд░рд╛рд╣рдХрд╛рдВрдЪреА рдХреНрд░рдорд╡рд╛рд░реА рд▓рд╛рд╡рд╛.

### рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕

```python
df = pd.read_csv("kunden.csv")
print(df["Einkommen"].median())
print(df[df["Alter"] > 40])
stats = df.describe().to_string()
prompt = f"Welche wirtschaftlichen Trends lassen sich erkennen?\n{stats}"
print(df.sort_values("Einkommen", ascending=False))
```
-

## рдпреБрдирд┐рдЯ 2 - рд╕реАрдПрд╕рд╡реНрд╣реА рдлрд╛рдпрд▓реАрдВрдмрджреНрджрд▓ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░

### рдЙрджрд╛рд╣рд░рдгреЗ

#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реЛрдкреА рдХреНрд╡реЗрд░реА

```python
frage = "Wie viele Kunden sind ├дlter als 30?"
antwort = len(df[df["Alter"] > 30])
print(antwort)
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рдПрд▓рдПрд▓рдПрдо рд╕рд╣ рдЙрддреНрддрд░

```python
stats = df.describe().to_string()
prompt = f"""Beantworte die Frage basierend auf diesen Daten:
{stats}
Frage: Wie viele Kunden sind ├дlter als 30?"""
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдкреНрд░рд╡рд╛рд╣ рдЕреЕрдк

```python
import streamlit as st

file = st.file_uploader("CSV hochladen", type="csv")
if file:
    df = pd.read_csv(file)
    frage = st.text_input("Frage:")
    if frage:
        stats = df.describe().to_string()
        prompt = f"{frage}\nDaten:\n{stats}"
        r = requests.post("http://localhost:11434/api/generate",
                          json={"model": "llama2", "prompt": prompt})
        st.write("Antwort:", r.json()["response"])
```
#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реЛрдкреА рдХреНрд╡реЗрд░реА

```python
# Datei: einheit42_einfache_abfrage.py
import pandas as pd
df = pd.read_csv("kunden.csv")
frage = "Wie viele Kunden sind ├дlter als 30?"
antwort = len(df[df["Alter"] > 30])
print(antwort)
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рдПрд▓рдПрд▓рдПрдорд╕рд╣ рдкреНрд░рддреНрдпреБрддреНрддрд░ рджреНрдпрд╛ (рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗ)

```python
# Datei: einheit42_llm_antwort.py
import pandas as pd
from lib.helper_ollama import ollama

df = pd.read_csv("kunden.csv")
stats = df.describe().to_string()
prompt = f"Beantworte die Frage basierend auf diesen Daten:\n{stats}\nFrage: Wie viele Kunden sind ├дlter als 30?"
result = ollama.generate(prompt)
print(result)
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗрд╕рд╣ рдкреНрд░рд╡рд╛рд╣ рдЕреЕрдк

```python
# Datei: einheit42_streamlit_app.py
import streamlit as st
import pandas as pd
from lib.helper_ollama import ollama

file = st.file_uploader("CSV hochladen", type="csv")
if file:
    df = pd.read_csv(file)
    frage = st.text_input("Frage:")
    if frage:
        stats = df.describe().to_string()
        prompt = f"{frage}\nDaten:\n{stats}"
        result = ollama.generate(prompt)
        st.write("Antwort:", result)
```
### рд╡реНрдпрд╛рдпрд╛рдо

- рдЕрдВрдорд▓рдмрдЬрд╛рд╡рдгреА: "рд╕реАрдПрд╕рд╡реНрд╣реАрдордзреНрдпреЗ рдХрд┐рддреА рд╡реЗрдЧрд╡реЗрдЧрд│реНрдпрд╛ рд╢рд╣рд░реЗ рдЖрд╣реЗрдд?"
- рдПрдХ рдлрдВрдХреНрд╢рди рд▓рд┐рд╣рд╛ `рдЙрддреНрддрд░_рдХреНрд╡реЗрд╢рди (рдбреАрдПрдл, рдкреНрд░рд╢реНрди)` рдЬреЗ рдкрд╛рдВрдбрд╛рд╕ + рдУрд▓рд╛рдорд╛ рдПрдХрддреНрд░ рдХрд░рддреЗ.
- рдпрд╛ рдкреНрд░рд╢реНрдирд╛рдЪреА рдЪрд╛рдЪрдгреА рдШреНрдпрд╛: тАЬрдХреЛрдгрддреНрдпрд╛ рдЧреНрд░рд╛рд╣рдХрд╛рдЪреЗ рд╕рд░реНрд╡рд╛рдзрд┐рдХ рдЙрддреНрдкрдиреНрди рдЖрд╣реЗ?тАЭ

### рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕

```python
# Anzahl St├дdte
print(df["Stadt"].nunique())

# Funktion
def answer_question(df, frage):
    stats = df.describe().to_string()
    prompt = f"Frage: {frage}\nDaten:\n{stats}"
    r = requests.post("http://localhost:11434/api/generate",
                      json={"model": "llama2", "prompt": prompt})
    return r.json()["response"]

print(answer_question(df, "Was ist der Durchschnitt des Alters?"))

# Pandas-L├╢sung
print(df.loc[df["Einkommen"].idxmax()])
```
-

## рдпреБрдирд┐рдЯ 3 - рдкреНрд░рд╡рд╛рд╣рд╛рд╕рд╣ рдПрдЖрдп рдбреЕрд╢рдмреЛрд░реНрдб

### рдЙрджрд╛рд╣рд░рдгреЗ

#### рдЙрджрд╛рд╣рд░рдг 1 - рдмрд╛рд░ рдЪрд╛рд░реНрдЯ

```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
df["Sales"].plot(kind="bar", ax=ax)
st.pyplot(fig)
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд╣рд┐рд╕реНрдЯреЛрдЧреНрд░рд╛рдо

```python
fig, ax = plt.subplots()
df["Age"].hist(ax=ax, bins=10)
st.pyplot(fig)
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдПрд▓рдПрд▓рдПрдо рдЯрд┐рдкреНрдкрдгреА

```python
stats = df.describe().to_string()
prompt = f"Erkl├дre die wichtigsten Trends:\n{stats}"
```
#### рдЙрджрд╛рд╣рд░рдг 1 - рдмрд╛рд░ рдЪрд╛рд░реНрдЯ (рдкреНрд░рд╡рд╛рд╣)

```python
# Datei: einheit43_balkendiagramm.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("sales.csv")
fig, ax = plt.subplots()
df["Sales"].plot(kind="bar", ax=ax)
st.pyplot(fig)
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд╣рд┐рд╕реНрдЯреЛрдЧреНрд░рд╛рдо (рдкреНрд░рд╡рд╛рд╣)

```python
# Datei: einheit43_histogramm.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("sales.csv")
fig, ax = plt.subplots()
df["Age"].hist(ax=ax, bins=10)
st.pyplot(fig)
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдПрд▓рдПрд▓рдПрдо рдЯрд┐рдкреНрдкрдгреА (рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗ)

```python
# Datei: einheit43_llm_kommentar.py
import pandas as pd
from lib.helper_ollama import ollama

df = pd.read_csv("sales.csv")
stats = df.describe().to_string()
prompt = f"Erkl├дre die wichtigsten Trends:\n{stats}"
result = ollama.generate(prompt)
print(result)
```
#### рдЙрджрд╛рд╣рд░рдг 4 - рджреЛрди рдЧрдЯрд╛рдВрдЪреА рддреБрд▓рдирд╛

```python
city1, city2 = "Berlin", "Hamburg"
df1 = df[df["City"] == city1]
df2 = df[df["City"] == city2]
prompt = f"Vergleiche {city1} und {city2}:\n{df1.describe().to_string()}\n{df2.describe().to_string()}"
```
### рд╡реНрдпрд╛рдпрд╛рдо

- рд╡рдп рд╡рд┐рддрд░рдг (рд╣рд┐рд╕реНрдЯреЛрдЧреНрд░рд╛рдо) рдЖрдгрд┐ рдПрд▓рдПрд▓рдПрдо рд╡рд┐рд╢реНрд▓реЗрд╖рдгрд╛рд╕рд╣ рдбреЕрд╢рдмреЛрд░реНрдб рддрдпрд╛рд░ рдХрд░рд╛.
- рд╡рд┐рдХреНрд░реА рдЪрд╛рд░реНрдЯ рдЖрдгрд┐ рд╡рдп рдЪрд╛рд░реНрдЯ рджрд░рдореНрдпрд╛рди рд╕реНрд╡рд┐рдЪ рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА рдбреНрд░реЙрдкрдбрд╛рдЙрди рддрдпрд╛рд░ рдХрд░рд╛.
- рдПрдХ рд╡реИрд╢рд┐рд╖реНрдЯреНрдп рдЬреЛрдбрд╛: тАЬрдЙрддреНрдкрдиреНрдирд╛рддреАрд▓ рдкреБрд░реБрд╖ рд╡рд┐. рд╕реНрддреНрд░рд┐рдпрд╛рдВрдЪреА рддреБрд▓рдирд╛ рдХрд░рд╛тАЭ.

### рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕

```python
# Histogramm
fig, ax = plt.subplots()
df["Age"].hist(ax=ax)
st.pyplot(fig)

# Auswahl
chart = st.selectbox("Diagramm w├дhlen", ["Umsatz", "Alter"])
if chart == "Umsatz":
    df["Sales"].plot(kind="bar")
else:
    df["Age"].hist()

# Geschlechtervergleich
male = df[df["Gender"] == "Male"]
female = df[df["Gender"] == "Female"]
prompt = f"Vergleiche Einkommen von M├дnnern und Frauen:\n{male.describe()}\n{female.describe()}"
```
-

## рдпреБрдирд┐рдЯ 4 - рдЙрдкрдпреЛрдЬрди

### рдЙрджрд╛рд╣рд░рдгреЗ

#### рдЙрджрд╛рд╣рд░рдг 1 - рдЕреЕрдк рдкреНрд░рд╛рд░рдВрдн рдХрд░рд╛

```bash
streamlit run app.py
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рдЖрд╡рд╢реНрдпрдХрддрд╛.рдЯреАрдПрдХреНрд╕рдЯреА

```
streamlit
pandas
requests
matplotlib
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдбреЙрдХрд░рдлрд╛рдЗрд▓

```dockerfile
FROM python:3.10
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```
#### рдЙрджрд╛рд╣рд░рдг 4 - рдбреЙрдХрд░рд╕рд╣ рдЙрдкрдпреЛрдЬрди

```bash
docker build -t myapp .
docker run -p 8501:8501 myapp
```
#### рдЙрджрд╛рд╣рд░рдг 1 - рдЕреЕрдк рдкреНрд░рд╛рд░рдВрдн рдХрд░рд╛

```bash
streamlit run app.py
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рдЖрд╡рд╢реНрдпрдХрддрд╛.рдЯреАрдПрдХреНрд╕рдЯреА

```text
streamlit
pandas
matplotlib
5тАФCapstone-Projekte.ai-content-studio_1.lib.ollama
```
#### рдЙрджрд╛рд╣рд░рдг 3 - рдбреЙрдХрд░рдлрд╛рдЗрд▓

```dockerfile
FROM python:3.10
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```
#### рдЙрджрд╛рд╣рд░рдг 4 - рдбреЙрдХрд░рд╕рд╣ рдЙрдкрдпреЛрдЬрди

```bash
docker build -t myapp .
docker run -p 8501:8501 myapp
```
### рд╡реНрдпрд╛рдпрд╛рдо

- рдЖрдкрд▓реНрдпрд╛ рд╕реНрд╡рдд: рдЪреНрдпрд╛ рдЕреЕрдкрд╕рд╛рдареА рдЖрд╡рд╢реНрдпрдХрддрд╛ рддрдпрд╛рд░ рдХрд░рд╛.
- рдПрдХ рдбреЙрдХрд░ рдкреНрд░рддрд┐рдорд╛ рддрдпрд╛рд░ рдХрд░рд╛ рдЖрдгрд┐ рд╕реНрдерд╛рдирд┐рдХ рдкрд╛рддрд│реАрд╡рд░ рдЪрд╛рд▓рд╡рд╛.
- рд╕реНрдЯреНрд░реАрдорд▓реАрдЯ рдХреНрд▓рд╛рдКрдб (рдЧрд┐рдЯрд╣рдм тЖТ рд╕реНрдЯреНрд░реАрдорд▓рд┐рдЯ рдХреНрд▓рд╛рдКрдб) рд╡рд░ рдЕтАНреЕрдк рдкреНрд░рд╛рд░рдВрдн рдХрд░рд╛.

### рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕

```text
# requirements.txt
streamlit
pandas
requests

# Docker
docker build -t meine-app .
docker run -p 8501:8501 meine-app
```
-

## рдпреБрдирд┐рдЯ 5 - рдмреЛрдирд╕: рдПрдХрд╛рдзрд┐рдХ рдбреЗрдЯрд╛ рд╕реНрд░реЛрддрд╛рдВрдордзреНрдпреЗ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░

### рдЙрджрд╛рд╣рд░рдгреЗ

#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реАрдПрд╕рд╡реНрд╣реА + рд╕рд╛рдорд╛рдиреНрдп рдкреНрд░рд╢реНрди

```python
faq = "Q: Was ist KI? A: Maschinen, die wie Menschen denken."
stats = df.describe().to_string()
prompt = f"""Beantworte die Frage basierend auf diesen Quellen:
FAQ: {faq}
CSV-Daten: {stats}
Frage: Was ist das Durchschnittsalter?"""
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд╕реАрдПрд╕рд╡реНрд╣реА + рдордЬрдХреВрд░ рджрд╕реНрддрдРрд╡рдЬ

```python
doc = open("info.txt").read()
prompt = f"""Verwende CSV + Dokument:
CSV: {df.describe().to_string()}
Dokument: {doc}
Frage: Welche Erkenntnisse gibt es?"""
```
#### рдЙрджрд╛рд╣рд░рдг 1 - рд╕реАрдПрд╕рд╡реНрд╣реА + рдПрдлрдПрдХреНрдпреВ (рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗ)

```python
# Datei: einheit45_csv_faq.py
import pandas as pd
from lib.helper_ollama import ollama

df = pd.read_csv("kunden.csv")
faq = "Q: Was ist KI? A: Maschinen, die wie Menschen denken."
stats = df.describe().to_string()
prompt = f"Beantworte die Frage basierend auf diesen Quellen:\nFAQ: {faq}\nCSV-Daten: {stats}\nFrage: Was ist das Durchschnittsalter?"
result = ollama.generate(prompt)
print(result)
```
#### рдЙрджрд╛рд╣рд░рдг 2 - рд╕реАрдПрд╕рд╡реНрд╣реА + рдордЬрдХреВрд░ рджрд╕реНрддрдРрд╡рдЬ (рдУрд▓рд╛рдорд╛ рдПрд╕рдбреАрдХреЗ)

```python
# Datei: einheit45_csv_text.py
import pandas as pd
from lib.helper_ollama import ollama

df = pd.read_csv("kunden.csv")
doc = open("info.txt").read()
prompt = f"Verwende CSV + Dokument:\nCSV: {df.describe().to_string()}\nDokument: {doc}\nFrage: Welche Erkenntnisse gibt es?"
result = ollama.generate(prompt)
print(result)
```
### рд╡реНрдпрд╛рдпрд╛рдо

- рдЧреНрд░рд╛рд╣рдХ рдбреЗрдЯрд╛рд╕рд╣ рд╕реАрдПрд╕рд╡реНрд╣реА рд▓реЛрдб рдХрд░рд╛ рдЖрдгрд┐ рддреНрдпрд╛рд╕ рд╕рд╛рдорд╛рдиреНрдп рдкреНрд░рд╢реНрди рдлрд╛рдИрд▓рд╕рд╣ рдПрдХрддреНрд░ рдХрд░рд╛.
- рдПрдХрд╛рдЪ рд╡реЗрд│реА рджреЛрдиреНрд╣реА рд╕реНрддреНрд░реЛрддрд╛рдВрдЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рдгрд╛рд░реЗ рдПрдХ рдЕтАНреЕрдк рд▓рд┐рд╣рд╛.
- рдкреНрд░рд╢реНрди рд╡рд┐рдЪрд╛рд░рд╛: "рдХреЛрдгрддреНрдпрд╛ рд╢рд╣рд░рд╛рдЪреА рд╕рд░реНрд╡рд╛рдзрд┐рдХ рд╡рд┐рдХреНрд░реА рдЖрд╣реЗ рдЖрдгрд┐ рдПрдлрдПрдХреНрдпреВ рдбреЗрдЯрд╛рд╕рд╣ рддреЗ рдХрд╕реЗ рдлрд┐рдЯ рдЖрд╣реЗ?"

### рд╕реЛрд▓реНрдпреВрд╢рдиреНрд╕

```python
faq = open("faq.txt").read()
stats = df.describe().to_string()
frage = "Welche Stadt hat den h├╢chsten Umsatz und wie passt das zu den FAQ-Daten?"

prompt = f"""FAQ: {faq}
CSV: {stats}
Frage: {frage}"""
```
-

## рдпреБрдирд┐рдЯ 6 - рд╕рд╛рд░рд╛рдВрд╢

рджрд┐рд╡рд╕ 4 рдирдВрддрд░, рд╡рд┐рджреНрдпрд╛рд░реНрдереА рд╣реЗ рдХрд░реВ рд╢рдХрддрд╛рдд:

- рдкрд╛рдВрдбрд╛рд╕рд╣ рд╕реАрдПрд╕рд╡реНрд╣реА/рдПрдХреНрд╕реЗрд▓ рдкреНрд░рдХреНрд░рд┐рдпрд╛
- рдбреЗрдЯрд╛ рдмрджреНрджрд▓ рдкреНрд░рд╢реНрдиреЛрддреНрддрд░рд╛рдВрд╕рд╛рдареА рдПрд▓рдПрд▓рдПрдордПрд╕ рд╡рд╛рдкрд░рд╛
- рдбреЗрдЯрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдгрд╛рд╕рд╛рдареА рдкреНрд░рд╡рд╛рд╣рд┐рдд рдЕреЕрдкреНрд╕ рддрдпрд╛рд░ рдХрд░рд╛
- рдиреИрд╕рд░реНрдЧрд┐рдХ рднрд╛рд╖реЗрддреАрд▓ рд╕реАрдПрд╕рд╡реНрд╣реА рдбреЗрдЯрд╛ рдХреНрд╡реЗрд░реА
- рдПрдХрд╛рдзрд┐рдХ рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд рдПрдХрддреНрд░ рдХрд░рд╛
- рдбреЙрдХрд░рд╕рд╣ рдЕреЕрдкреНрд╕ рдХрдВрдЯреЗрдирд░рд┐рдЭ рдХрд░рд╛
- рд╕реНрдЯреНрд░реАрдорд▓реАрдЯ рдХреНрд▓рд╛рдКрдбрд╡рд░ рдЕреЕрдкреНрд╕ рдЙрдкрдпреЛрдЬрд┐рдд рдХрд░рд╛

-

## рдпреБрдирд┐рдЯ 7 - рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк

### рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк 1: рдмреБрджреНрдзрд┐рдорд╛рди рд╡реНрдпрд╡рд╕рд╛рдп рдмреБрджреНрдзрд┐рдорддреНрддрд╛ рдбреЕрд╢рдмреЛрд░реНрдб

** рдХрд╛рд░реНрдп: ** рдХрдВрдкрдиреАрдЪреНрдпрд╛ рдбреЗрдЯрд╛рдЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рдгрд╛рд░реЗ рдЖрдгрд┐ рд╡реНрдпрд╡рд╕рд╛рдпрд╛рдЪреНрдпрд╛ рд╢рд┐рдлрд╛рд░рд╕реА рдкреНрд░рджрд╛рди рдХрд░рдгрд╛рд░реЗ рдбреЕрд╢рдмреЛрд░реНрдб рддрдпрд╛рд░ рдХрд░рд╛.

** рд╕рдорд╛рдзрд╛рди: **

```python
import streamlit as st
import pandas as pd
import plotly.express as px
from lib.helper_ollama import ollama

st.title("Business Intelligence Dashboard")

# Daten hochladen
uploaded_file = st.file_uploader("Gesch├дftsdaten (CSV) hochladen", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    
    # Grundlegende Visualisierung
    st.subheader("Daten├╝bersicht")
    st.dataframe(df.head())
    
    # Automatische Diagramme
    if st.button("Automatische Visualisierung"):
        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
        if len(numeric_cols) >= 2:
            fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1])
            st.plotly_chart(fig)
    
    # KI-basierte Analyse
    st.subheader("KI-Gesch├дftsanalyse")
    analyse_typ = st.selectbox("Analyse-Typ:", 
                              ["Umsatztrends", "Kundenverhalten", "Kostenoptimierung", "Marktchancen"])
    
    if st.button("Analysieren"):
        stats = df.describe().to_string()
        
        if analyse_typ == "Umsatztrends":
            prompt = f"Analysiere diese Gesch├дftsdaten und identifiziere Umsatztrends. Gib konkrete Empfehlungen:\n{stats}"
        elif analyse_typ == "Kundenverhalten":
            prompt = f"Analysiere das Kundenverhalten basierend auf diesen Daten:\n{stats}"
        elif analyse_typ == "Kostenoptimierung":
            prompt = f"Identifiziere Kostenoptimierungsm├╢glichkeiten in diesen Daten:\n{stats}"
        else:
            prompt = f"Identifiziere neue Marktchancen basierend auf diesen Daten:\n{stats}"
        
        result = ollama.generate(prompt)
        st.write("**KI-Empfehlungen:**", result)
```
### рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк 2: рд╕реНрд╡рдпрдВрдЪрд▓рд┐рдд рдЕрд╣рд╡рд╛рд▓ рдЬрдирд░реЗрдЯрд░

** рдХрд╛рд░реНрдп: ** рд╡рд┐рд╡рд┐рдз рдбреЗрдЯрд╛ рд╕реНрд░реЛрддрд╛рдВрдХрдбреВрди рд╕реНрд╡рдпрдВрдЪрд▓рд┐рддрдкрдгреЗ рдЕрд╣рд╡рд╛рд▓ рд╡реНрдпреБрддреНрдкрдиреНрди рдХрд░рд╛.

** рд╕рдорд╛рдзрд╛рди: **

```python
import streamlit as st
import pandas as pd
from datetime import datetime
from lib.helper_ollama import ollama

st.title("Automatischer Report Generator")

# Multiple Datenquellen
st.subheader("Datenquellen hinzuf├╝gen")
files = st.file_uploader("CSV-Dateien hochladen", type="csv", accept_multiple_files=True)

if files:
    data_summaries = []
    
    for i, file in enumerate(files):
        df = pd.read_csv(file)
        st.write(f"**Datei {i+1}: {file.name}**")
        st.write(f"Shape: {df.shape}")
        
        # Kurze Statistik
        summary = f"Datei: {file.name}\nZeilen: {df.shape[0]}\nSpalten: {df.shape[1]}\nStatistik:\n{df.describe().to_string()}"
        data_summaries.append(summary)
    
    # Report-Typ w├дhlen
    report_typ = st.selectbox("Report-Typ:", 
                             ["Executive Summary", "Detailanalyse", "Vergleichsbericht", "Trend-Report"])
    
    if st.button("Report generieren"):
        all_data = "\n\n".join(data_summaries)
        
        prompt = f"""Erstelle einen professionellen {report_typ} basierend auf folgenden Daten:

{all_data}

Der Report soll enthalten:
1. Management Summary
2. Wichtigste Erkenntnisse
3. Empfehlungen
4. Risiken und Chancen
5. N├дchste Schritte

Format: Professioneller Gesch├дftsbericht"""
        
        result = ollama.generate(prompt)
        
        st.subheader(f"{report_typ} - {datetime.now().strftime('%d.%m.%Y')}")
        st.write(result)
        
        # Download-Button
        st.download_button(
            label="Report als Textdatei herunterladen",
            data=result,
            file_name=f"report_{datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain"
        )
```
### рдорд┐рдиреА рдкреНрд░реЛрдЬреЗрдХреНрдЯ 3: рд╕реНрдорд╛рд░реНрдЯ рдбреЗрдЯрд╛ рдХреНрд╡реЗрд░реА рдЗрдВрдЯрд░рдлреЗрд╕

** рдХрд╛рд░реНрдп: ** рд╕рдВрд░рдЪрд┐рдд рдбреЗрдЯрд╛рд╡рд░ рдиреИрд╕рд░реНрдЧрд┐рдХ рднрд╛рд╖реЗрдЪреЗ рдХреНрд╡реЗрд░реА рд╕рдХреНрд╖рдо рдХрд░рд╛.

** рд╕рдорд╛рдзрд╛рди: **

```python
import streamlit as st
import pandas as pd
import sqlite3
from lib.helper_ollama import ollama

st.title("Smart Data Query Interface")

# Daten laden
uploaded_file = st.file_uploader("CSV-Datei hochladen", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("**Datenvorschau:**")
    st.dataframe(df.head())
    
    # Spaltennamen anzeigen
    st.write("**Verf├╝gbare Spalten:**", ", ".join(df.columns.tolist()))
    
    # Nat├╝rlichsprachliche Abfrage
    st.subheader("Stelle eine Frage zu den Daten")
    question = st.text_input("Frage (z.B. 'Was ist der Durchschnittswert der Spalte X?'):")
    
    if st.button("Abfrage ausf├╝hren") and question:
        # Erst KI nach SQL-Query fragen
        schema_info = f"Tabelle mit Spalten: {', '.join(df.columns)}\nDatentypen: {df.dtypes.to_string()}"
        
        sql_prompt = f"""Konvertiere diese nat├╝rlichsprachliche Frage in eine SQL-Query:

Schema: {schema_info}
Frage: {question}

Gib nur die SQL-Query zur├╝ck, ohne Erkl├дrung:"""
        
        sql_query = ollama.generate(sql_prompt).strip()
        st.write("**Generierte SQL-Query:**", sql_query)
        
        try:
            # SQL ausf├╝hren (vereinfacht mit pandas)
            # In Realit├дt w├╝rde man eine echte SQL-Engine verwenden
            conn = sqlite3.connect(':memory:')
            df.to_sql('data', conn, index=False)
            
            result_df = pd.read_sql_query(sql_query.replace('data', 'data'), conn)
            st.write("**Ergebnis:**")
            st.dataframe(result_df)
            
        except Exception as e:
            st.error(f"Fehler bei SQL-Ausf├╝hrung: {e}")
            
            # Fallback: Direkte Antwort von KI
            fallback_prompt = f"""Beantworte diese Frage basierend auf den Daten:

Datenstatistik: {df.describe().to_string()}
Spalten: {df.columns.tolist()}
Frage: {question}"""
            
            fallback_result = ollama.generate(fallback_prompt)
            st.write("**KI-Antwort:**", fallback_result)
```
### рдорд┐рдиреА рдкреНрд░реЛрдЬреЗрдХреНрдЯ 4: рдорд▓реНрдЯреА-рд╕реЛрд░реНрд╕ рдбреЗрдЯрд╛ рдлреНрдпреВрдЬрди

** рдХрд╛рд░реНрдп: ** рдмреБрджреНрдзрд┐рдорд╛рдирдкрдгреЗ рд╡реЗрдЧрд╡реЗрдЧрд│реНрдпрд╛ рд╕реНрддреНрд░реЛрддрд╛рдВрдХрдбреАрд▓ рдбреЗрдЯрд╛ рдПрдХрддреНрд░ рдЖрдгрд┐ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рд╛.

** рд╕рдорд╛рдзрд╛рди: **

```python
import streamlit as st
import pandas as pd
import json
from lib.helper_ollama import ollama

st.title("Multi-Source Data Fusion")

st.write("Lade verschiedene Datenquellen und lasse sie von der KI intelligent kombinieren.")

# Verschiedene Datentypen
col1, col2 = st.columns(2)

with col1:
    st.subheader("Strukturierte Daten")
    csv_file = st.file_uploader("CSV-Datei", type="csv")
    
with col2:
    st.subheader("Unstrukturierte Daten")
    text_file = st.file_uploader("Text-Datei", type="txt")

# JSON-Eingabe
json_text = st.text_area("JSON-Daten (optional):")

# Kombinationsanalyse
if csv_file or text_file or json_text:
    sources = []
    
    if csv_file:
        df = pd.read_csv(csv_file)
        csv_summary = f"CSV-Daten:\nShape: {df.shape}\nSpalten: {df.columns.tolist()}\nStatistik:\n{df.describe().to_string()}"
        sources.append(csv_summary)
        st.write("**CSV geladen:**", df.shape)
    
    if text_file:
        text_content = text_file.read().decode()
        text_summary = f"Text-Daten:\nL├дnge: {len(text_content)} Zeichen\nInhalt (Auszug): {text_content[:500]}..."
        sources.append(text_summary)
        st.write("**Text geladen:**", len(text_content), "Zeichen")
    
    if json_text:
        try:
            json_data = json.loads(json_text)
            json_summary = f"JSON-Daten:\nStruktur: {json.dumps(json_data, indent=2)[:500]}..."
            sources.append(json_summary)
            st.write("**JSON geparst:** тЬЕ")
        except:
            st.warning("JSON nicht valid")
    
    # Fusion und Analyse
    if st.button("Daten fusionieren und analysieren") and sources:
        fusion_prompt = f"""Analysiere und kombiniere diese verschiedenen Datenquellen intelligent:

{chr(10).join(sources)}

Aufgaben:
1. Identifiziere Verbindungen zwischen den Datenquellen
2. Finde Muster und Trends
3. Erkenne Widerspr├╝che oder Anomalien
4. Gib zusammenfassende Insights
5. Empfehle weitere Analyseschritte

Antwort als strukturierter Bericht:"""
        
        result = ollama.generate(fusion_prompt)
        st.subheader("Fusionsanalyse")
        st.write(result)
        
        # Zus├дtzlich: Spezifische Fragen stellen
        custom_question = st.text_input("Spezifische Frage zu den kombinierten Daten:")
        if st.button("Frage stellen") and custom_question:
            question_prompt = f"Beantworte diese Frage basierend auf allen Datenquellen:\n\n{chr(10).join(sources)}\n\nFrage: {custom_question}"
            answer = ollama.generate(question_prompt)
            st.write("**Antwort:**", answer)
```
### рдорд┐рдиреА рдкреНрд░рдХрд▓реНрдк 5: рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЗрдВрдЯрд░рдлреЗрд╕

** рдорд┐рд╢рди: ** рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рд╕рд╛рдзреНрдпрд╛ рдЕрдВрджрд╛рдЬ рдЖрдгрд┐ рдЯреНрд░реЗрдВрдбрд╕рд╛рдареА рдПрдЖрдп рд╡рд╛рдкрд░рд╛.

** рд╕рдорд╛рдзрд╛рди: **

```python
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from lib.helper_ollama import ollama

st.title("Predictive Analytics Interface")

uploaded_file = st.file_uploader("Zeitreihen-Daten (CSV) hochladen", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    
    st.subheader("Datenvorschau")
    st.dataframe(df.head())
    
    # Spalten f├╝r Analyse ausw├дhlen
    date_col = st.selectbox("Datums-Spalte:", df.columns)
    value_col = st.selectbox("Wert-Spalte:", df.select_dtypes(include=['float64', 'int64']).columns)
    
    if date_col and value_col:
        # Daten vorbereiten
        try:
            df[date_col] = pd.to_datetime(df[date_col])
            df_sorted = df.sort_values(date_col)
            
            # Visualisierung
            fig = px.line(df_sorted, x=date_col, y=value_col, title="Zeitreihen-Verlauf")
            st.plotly_chart(fig)
            
            # Vorhersage-Parameter
            col1, col2 = st.columns(2)
            with col1:
                prediction_days = st.slider("Vorhersage f├╝r X Tage:", 1, 90, 30)
            with col2:
                confidence_level = st.selectbox("Konfidenz-Level:", ["Niedrig", "Mittel", "Hoch"])
            
            if st.button("Vorhersage generieren"):
                # Datenanalyse f├╝r KI
                recent_data = df_sorted.tail(20)
                data_summary = f"""
Letzte 20 Datenpunkte:
{recent_data[[date_col, value_col]].to_string()}

Statistiken:
- Mittelwert: {df[value_col].mean():.2f}
- Standardabweichung: {df[value_col].std():.2f}
- Trend (letzte 5 vs vorherige 5): {recent_data[value_col].tail(5).mean() - recent_data[value_col].head(5).mean():.2f}
- Min: {df[value_col].min():.2f}
- Max: {df[value_col].max():.2f}
"""
                
                prediction_prompt = f"""Analysiere diese Zeitreihen-Daten und gib eine Vorhersage f├╝r die n├дchsten {prediction_days} Tage:

{data_summary}

Aufgaben:
1. Identifiziere Trends und Muster
2. Sch├дtze wahrscheinliche Werte f├╝r die n├дchsten {prediction_days} Tage
3. Erkenne Saisonalit├дt oder Zyklen
4. Bewerte Risiken und Unsicherheiten
5. Gib konkrete Zahlenwerte als Prognose

Konfidenz-Level: {confidence_level}

Format die Antwort als:
- Trend-Analyse
- Vorhersage (numerische Werte)
- Konfidenz-Bewertung
- Einflussfaktoren
- Empfehlungen"""
                
                prediction = ollama.generate(prediction_prompt)
                
                st.subheader(f"Vorhersage f├╝r {prediction_days} Tage")
                st.write(prediction)
                
                # Zus├дtzlich: What-If Szenarien
                st.subheader("What-If Analyse")
                scenario = st.text_input("Beschreibe ein Szenario (z.B. '20% Umsatzsteigerung'):")
                
                if st.button("Szenario analysieren") and scenario:
                    scenario_prompt = f"""Analysiere dieses What-If Szenario basierend auf den historischen Daten:

Historische Daten: {data_summary}
Szenario: {scenario}

Wie w├╝rde sich das auf die Vorhersage auswirken? Gib konkrete Zahlen und Wahrscheinlichkeiten."""
                    
                    scenario_result = ollama.generate(scenario_prompt)
                    st.write("**Szenario-Analyse:**", scenario_result)
                    
        except Exception as e:
            st.error(f"Fehler bei der Datenverarbeitung: {e}")
```
- рдЪрд╛рд░реНрдЯ + рдПрдЖрдп рдЯрд┐рдкреНрдкрдгреНрдпрд╛рдВрд╕рд╣ рдбреЕрд╢рдмреЛрд░реНрдб рддрдпрд╛рд░ рдХрд░рд╛
- рдЕреЕрдкреНрд╕ рдЙрдкрдпреЛрдЬрд┐рдд рдХрд░рд╛ (рдкреНрд░рд╡рд╛рд╣ рдХреНрд▓рд╛рдКрдб, рдбреЙрдХрд░)
- рдПрдХрд╛рдзрд┐рдХ рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд рдПрдХрддреНрд░ рдХрд░рд╛